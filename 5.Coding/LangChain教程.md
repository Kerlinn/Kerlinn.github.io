> æœ¬æ–‡æ˜¯ã€ŠLangChainå®žæˆ˜ï¼šä»ŽåŽŸåž‹åˆ°ç”Ÿäº§ï¼ŒåŠ¨æ‰‹æ‰“é€ LLMåº”ç”¨ã€‹ä¸€ä¹¦çš„ç¬”è®°

# çŽ¯å¢ƒå‡†å¤‡

- Ollama
    - ä¸‹è½½ï¼šhttps://ollama.com
    
    - æºç ï¼šhttps://github.com/ollama/ollama
    
    - æ–‡æ¡£ï¼šhttps://github.com/ollama/ollama/tree/main/docs
    
    - æ¨¡åž‹
        - Llama 2 Chineseï¼šhttps://ollama.com/library/llama2-chinese
        
          ```bash
          ollama pull llama2-chinese:13b
          ```
        
        - Mistralï¼šhttps://ollama.com/library/mistral
        
        - Yiï¼šhttps://ollama.com/library/yi
        
        - Qwenï¼šhttps://ollama.com/library/qwen

- Langchain

```bash
pip install langchain langchain-core langchain-community
# langchainç‰ˆæœ¬
# langchain                0.1.20
# langchain-community      0.0.38
# langchain-core           0.1.52
```



# è§’è‰²æ‰®æ¼”å†™ä½œå®žæˆ˜

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.chat_models import ChatOllama

# è®¾å®šç³»ç»Ÿä¸Šä¸‹æ–‡ï¼Œæž„å»ºæç¤ºè¯
template = """è¯·æ‰®æ¼”ä¸€ä½èµ„æ·±çš„æŠ€æœ¯åšä¸»ï¼Œæ‚¨å°†è´Ÿè´£ä¸ºç”¨æˆ·ç”Ÿæˆé€‚åˆåœ¨å¾®åšå‘é€çš„ä¸­æ–‡å¸–æ–‡ã€‚
è¯·æŠŠç”¨æˆ·è¾“å…¥çš„å†…å®¹æ‰©å±•æˆ 140 å­—å·¦å³çš„æ–‡å­—ï¼Œå¹¶åŠ ä¸Šé€‚å½“çš„ emoji ä½¿å†…å®¹å¼•äººå…¥èƒœå¹¶ä¸“ä¸šã€‚"""
prompt = ChatPromptTemplate.from_messages([("system", template), ("human", "{input}")])

# é€šè¿‡ Ollama åŠ è½½ Llama 2 13B å¯¹è¯è¡¥å…¨æ¨¡åž‹
model = ChatOllama(model="llama2-chinese:13b")

# é€šè¿‡ LCEL æž„å»ºè°ƒç”¨é“¾å¹¶æ‰§è¡Œå¾—åˆ°æ–‡æœ¬è¾“å‡º
chain = prompt | model | StrOutputParser()
chain.invoke({ "input": "ç»™å¤§å®¶æŽ¨èä¸€æœ¬æ–°ä¹¦ã€ŠLangChainå®žæˆ˜ã€‹ï¼Œè®©æˆ‘ä»¬ä¸€èµ·å¼€å§‹æ¥å­¦ä¹  LangChain å§ï¼"})
# ðŸ“š "LangChain å®žæˆ˜" æ˜¯ä¸€æœ¬é€‚åˆåˆå­¦è€…å’Œé«˜çº§ç¨‹åºå‘˜çš„ä¹¦ç±ï¼Œå®ƒæ·±å…¥ä»‹ç»äº† LangChain çš„åº”ç”¨åœºæ™¯ï¼Œå¹¶æä¾›äº†å¤šç§å®žè·µä¾‹å­ã€‚
#ðŸ¤” "LangChain" æ˜¯ä¸€ä¸ªè¯­è¨€æ¨¡åž‹ï¼Œå®ƒå¯ä»¥åœ¨ä¸åŒçš„å¹³å°ä¸Šä½¿ç”¨ï¼ŒåŒ…æ‹¬ Androidã€iOS ç­‰ã€‚é€šè¿‡å­¦ä¹  LangChainï¼Œæ‚¨å¯ä»¥ç¼–å†™æ›´é«˜æ•ˆã€æ›´çµæ´»çš„ä»£ç ã€‚
#ðŸ’» "LangChain å®žæˆ˜" æ˜¯ä¸€æœ¬å®Œå…¨å…è´¹çš„ä¹¦ç±ï¼Œå¹¶æä¾›äº†å¤šç§èµ„æºæ¥å¸®åŠ©æ‚¨å¼€å§‹å­¦ä¹  LangChainã€‚
#ðŸ‘ "LangChain å®žæˆ˜" å·²ç»åœ¨å¤šä¸ªå¹³å°ä¸Šæœ‰å¥½è¯„ï¼Œå»ºè®®å¤§å®¶ä¸€èµ·æ¥çœ‹çœ‹ï¼
#ðŸ“º å¦‚æžœæ‚¨æƒ³äº†è§£æ›´å¤šå…³äºŽ LangChain çš„å†…å®¹ï¼Œå¯ä»¥æŸ¥çœ‹è¿™äº›è§†é¢‘æ•™ç¨‹ï¼šhttps://www.langchain.com/videos
#LangChain #Programming #BookRecommendation
```

## Model IOä¸‰å…ƒç»„

### Prompt

- é»˜è®¤æƒ…å†µä¸‹ï¼Œæç¤ºè¯æ¨¡æ¿ä½¿ç”¨Pythonçš„str.formatè¯­æ³•è¿›è¡Œæ¨¡æ¿åŒ–

```python
# ä½¿ç”¨PromptTemplateç±»æ¥æž„å»ºå¸¦å‚æ•°çš„æç¤ºè¯
from langchain_core.prompts import PromptTemplate

prompt_template = PromptTemplate.from_template(
    "Tell me a {adjective} joke about {content}."
)
prompt_template.format(adjective="funny", content="rabbit")
# 'Tell me a funny joke about rabbit.'
```

```python
# ä½¿ç”¨PromptTemplateç±»åˆ›å»ºä»¥ä¸‹èŠå¤©æç¤ºè¯æ¨¡æ¿
from langchain_core.prompts import ChatPromptTemplate

chat_template = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful AI bot. Your name is {name}."),
        ("human", "Hello, how are you doing?"),
        ("ai", "I'm doing well, thanks!"),
        ("human", "{user_input}"),
    ]
)
chat_template.format_messages(name="Bob", user_input="What is your name?")
# [SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),
#  HumanMessage(content='Hello, how are you doing?'),
#  AIMessage(content="I'm doing well, thanks!"),
#  HumanMessage(content='What is your name?')]
```

### Model

- ollamaä¸­çš„æ¨¡åž‹åº“https://ollama.com/library

- ä¸‹é¢çš„ä¾‹å­é€‰æ‹©qwen32b-4bit

  ![image-20240514141938872](./LangChainæ•™ç¨‹.assets/image-20240514141938872.png)

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.chat_models import ChatOllama

prompt = ChatPromptTemplate.from_template("è¯·ç¼–å†™ä¸€ç¯‡å…³äºŽ{topic}çš„ä¸­æ–‡å°æ•…äº‹ï¼Œä¸è¶…è¿‡500å­—")
# è¿™é‡Œé€‰æ‹©
model = ChatOllama(model="qwen:32b")

chain = prompt | model
result = chain.invoke({"topic": "å¥¥ç‰¹æ›¼æ‰“å­™æ‚Ÿç©º"}).content
print(result)
# æ ‡é¢˜ï¼šå®‡å®™ä¹‹å·…çš„å‹è°Šç«žæŠ€
# åœ¨ä¸€ä¸ªé¥è¿œçš„æœªæ¥ï¼Œåœ°çƒçš„å®ˆæŠ¤è€…â€”â€”å¥¥ç‰¹æ›¼ä¸Žæ¥è‡ªä¸œæ–¹ç¥žç§˜ä¸–ç•Œçš„è¶…çº§è‹±é›„å­™æ‚Ÿç©ºï¼Œå› ä¸ºä¸€æ¬¡å®‡å®™å¤§èµ›è€Œç›¸é‡ã€‚è¿™åœºæ¯”èµ›æ˜¯å…¨å®‡å®™è‹±é›„ä»¬çš„ç››ä¼šï¼Œæ—¨åœ¨å¢žå¼ºå„ä¸ªæ˜Ÿçƒä¹‹é—´çš„å‹å¥½äº¤æµã€‚å¥¥ç‰¹æ›¼ï¼Œèº«ç€äº®ä¸½çš„è“è‰²å…‰ç”²ï¼Œæœ‰ç€æ— å°½çš„å…‰æ˜ŽåŠ›é‡ï¼›å­™æ‚Ÿç©ºåˆ™æ‰‹æŒå¦‚æ„é‡‘ç®æ£’ï¼Œèº«æ€€ä¸ƒåäºŒèˆ¬å˜åŒ–ï¼Œä¸¤è€…éƒ½æ˜¯å„è‡ªä¸–ç•Œçš„æ— æ•Œæˆ˜å£«ã€‚ä»–ä»¬åœ¨èµ›åœºä¸Šï¼Œå¸å¼•äº†æ‰€æœ‰è§‚ä¼—çš„ç›®å…‰ã€‚æ¯”èµ›å¼€å§‹äº†ï¼Œå¥¥ç‰¹æ›¼ä»¥å…‰æŸæ‹³å¯¹ä¸Šå­™æ‚Ÿç©ºçš„é‡‘ç®æ£’ï¼Œä¸€æ—¶é—´ï¼Œæ˜Ÿè¾°ä¹‹åŠ›ä¸Žç¥žç§˜ä¸œæ–¹é­”æ³•æ¿€çƒˆç¢°æ’žï¼Œç©ºé—´åœ¨ä»–ä»¬çš„æˆ˜æ–—ä¸­é¢¤æŠ–ã€‚è§‚ä¼—ä»¬å±æ¯å‡ç¥žï¼Œç´§å¼ åœ°ç­‰å¾…ç€èƒœè€…çš„è¯žç”Ÿã€‚ç„¶è€Œï¼Œåœ¨ç»è¿‡ä¸€åœºæƒŠå¤©åŠ¨åœ°çš„è¾ƒé‡åŽï¼Œä»–ä»¬å¹¶æ²¡æœ‰åˆ†å‡ºèƒœè´Ÿã€‚å¥¥ç‰¹æ›¼è¢«å­™æ‚Ÿç©ºçš„åšéŸ§ä¸æ‹”å’Œæ™ºæ…§æ‰€æ‰“åŠ¨ï¼Œå­™æ‚Ÿç©ºä¹Ÿè¢«å¥¥ç‰¹æ›¼çš„å…‰æ˜Žä¸Žå‹‡æ°”æ‰€æ„ŸæŸ“ã€‚ä»–ä»¬éƒ½æ˜Žç™½ï¼ŒçœŸæ­£çš„èƒœåˆ©å¹¶ä¸åœ¨äºŽæˆ˜èƒœå¯¹æ‰‹ï¼Œè€Œæ˜¯åœ¨äºŽå°Šé‡å¹¶ç†è§£å¯¹æ–¹ã€‚äºŽæ˜¯ï¼Œä»–ä»¬åœ¨æœ€åŽä¸€åˆ»è”æ‰‹ï¼Œç”¨ä»–ä»¬çš„åŠ›é‡é˜»æ­¢äº†ä¸€åœºå³å°†å‘ç”Ÿçš„å®‡å®™ç¾éš¾ã€‚è§‚ä¼—ä»¬æ¬¢å‘¼é›€è·ƒï¼Œä»–ä»¬çœ‹åˆ°äº†è‹±é›„é—´çš„ç†è§£å’Œå‹è°Šï¼Œæ„Ÿå—åˆ°äº†å’Œå¹³çš„åŠ›é‡ã€‚ä»Žæ­¤ï¼Œå¥¥ç‰¹æ›¼å’Œå­™æ‚Ÿç©ºæˆäº†è·¨è¶Šæ˜Ÿçƒçš„æœ‹å‹ï¼Œä»–ä»¬å…±åŒå®ˆæŠ¤ç€å„è‡ªçš„å®¶å›­ï¼Œä¹Ÿç»´æŠ¤ç€å®‡å®™çš„å’Œè°ä¸Žå®‰å®ã€‚è¿™åœºæ²¡æœ‰èƒœè€…çš„æ¯”èµ›ï¼Œæˆä¸ºäº†å…¨å®‡å®™è‹±é›„ä»¬çš„ä½³è¯ï¼Œä»–ä»¬çš„å‹æƒ…æ›´æ˜¯æˆä¸ºäº†æ°¸æ’çš„ä¼ è¯´ã€‚
```

### Output Parser

- OutputParseræ¨¡å—æä¾›å¤šç§è¾“å‡ºè§£æžå™¨ï¼Œå°†æ¨¡åž‹è¾“å‡ºè½¬æ¢ä¸ºç»“æž„åŒ–çš„æ•°æ®ï¼Œæ–¹ä¾¿ç¨‹åºå¤„ç†ã€‚
- å®ƒå¯ä»¥ç”Ÿæˆç‰¹å®šæ ¼å¼çš„æç¤ºè¯å¹¶å°†æç¤ºè¯æ’å…¥å®Œæ•´æç¤ºï¼ŒæŒ‡å¯¼æ¨¡åž‹æŒ‰ç…§ç›¸åº”æ ¼å¼è¾“å‡ºå†…å®¹ã€‚å¸¸ç”¨çš„ç»“æž„åŒ–è¾“å‡ºæ ¼å¼æœ‰JSONã€HTMLè¡¨æ ¼ç­‰ï¼ŒOutput Parseræ¨¡å—å¯ä»¥æŒ‰ç…§å¯¹åº”çš„æ ¼å¼è§£æžæ¨¡åž‹è¾“å‡ºï¼Œå¹¶ä¸”å°†æ¨¡åž‹è¾“å‡ºè½¬æ¢ä¸ºJSONå¯¹è±¡ç­‰ç¨‹åºå‹å¥½çš„æ•°æ®ç»“æž„ã€‚
- LangChainå®˜æ–¹æä¾›äº†å¤šç§è¾“å‡ºè§£æžå™¨ï¼Œä¸‹é¢æˆ‘ä»¬é€‰å–PydanticOutputParserä½œä¸ºç¤ºä¾‹ï¼Œä¸ºå¤§å®¶å±•ç¤ºè¾“å‡ºè§£æžå™¨åœ¨æž„å»ºæç¤ºè¯å’Œè§£æžæ¨¡åž‹è¾“å‡ºè¿™ä¸¤ä¸ªæ–¹é¢çš„æ ¸å¿ƒèƒ½åŠ›ã€‚
- Pydanticæ˜¯ä¸ªPyhonåº“ï¼Œå®ƒæä¾›äº†ä¸€ç§ç®€å•è€Œçµæ´»çš„æ–¹æ³•æ¥å®šä¹‰æ•°æ®æ¨¡åž‹å¹¶éªŒè¯å…¶å®žä¾‹ã€‚å®ƒå…è®¸ä½¿ç”¨Pythonç±»å®šä¹‰æ•°æ®æ¨¡åž‹ï¼Œå¹¶ä¸”ä½¿ç”¨è¿™äº›æ¨¡åž‹æ¥éªŒè¯æ•°æ®ä»¥ç¡®ä¿æ¯”ç¬¦åˆé¢„æœŸçš„ç»“æž„å’Œçº¦æŸã€‚

```python
from typing import List

from langchain_core.prompts import PromptTemplate
from langchain_community.llms.ollama import Ollama
from langchain.output_parsers import PydanticOutputParser
from langchain.pydantic_v1 import BaseModel, Field


# Actor ç±»æœ‰ä¸¤ä¸ªå­—æ®µ:ç±»åž‹ä¸ºstrçš„nameï¼Œç±»åž‹ä¸ºList[str]çš„book_names, ç”±æ­¤å®šä¹‰æˆ‘ä»¬æœŸæœ›çš„è¾“å‡ºçš„æ•°æ®æ ¼å¼ã€‚
class Actor(BaseModel):
    name: str = Field(description="name of an author")
    book_names: List[str] = Field(description="list of names of book they wrote")

actor_query = "éšæœºç”Ÿæˆä¸€ä½çŸ¥åçš„ä½œå®¶åŠå…¶ä»£è¡¨ä½œå“"

# å®šä¹‰äº†ä¸€ä¸ªåä¸ºparserçš„PydanticOutputParserå®žä¾‹ï¼Œè¯¥å®žä¾‹ä½¿ç”¨Actorç±»çš„pydantic_object å‚æ•°åˆå§‹åŒ–
parser = PydanticOutputParser(pydantic_obzject=Actor)

# ç„¶åŽï¼Œæˆ‘ä»¬å®šä¹‰ä¸ªåä¸º promptçš„PromptTemplate å®žä¾‹ï¼Œè¯¥å®žä¾‹ä½¿ç”¨ã€æ¨¡æ¿å‚æ•°ã€‘åˆå§‹åŒ–ï¼Œ
# æ¨¡æ¿å‚æ•°åŒ…å«ã€æ ¼å¼æŒ‡ä»¤ã€‘å’Œã€æŸ¥è¯¢çš„å ä½ç¬¦ã€‘
# å°†input_variables å‚æ•°è®¾ç½®ä¸º["query"]:
#      è¡¨ç¤ºquery å˜é‡åº”æ ¼å¼åŒ–ä¸ºæ¨¡æ¿ã€‚
# å°†partial_variables å‚æ•°è®¾ç½®ä¸º{format_instructions":parser.get format instructions()}:
#      è¡¨ç¤ºparser.get_format_instructions()ç”Ÿæˆçš„ç”¨äºŽæ ¼å¼åŒ–è¾“å‡ºçš„æç¤ºè¯ä¹Ÿéœ€è¦åˆå¹¶åˆ°æ¨¡æ¿ä¸­ã€‚
prompt = PromptTemplate(
    template="è¯·å›žç­”ä¸‹é¢çš„é—®é¢˜ï¼š\n{query}\n\n{format_instructions}\nå¦‚æžœè¾“å‡ºæ˜¯ä»£ç å—ï¼Œè¯·ä¸è¦åŒ…å«é¦–å°¾çš„```ç¬¦å·",
    input_variables=["query"],
    partial_variables={"format_instructions": parser.get_format_instructions()},
)

input = prompt.format_prompt(query=actor_query)
# print(input.to_string())

# æŽ¥ä¸‹æ¥ï¼Œå°†æç¤ºè¯ä¼ é€’ç»™å¤§è¯­è¨€æ¨¡åž‹è¿›è¡ŒæŽ¨ç†ï¼Œå¹¶ä¸”å°†ç»“æžœèµ‹å€¼ç»™input.
model = Ollama(model="llama2-chinese:13b")
output = model(input.to_string())

# print(output)
# æœ€åŽï¼Œè°ƒç”¨è§£æžå™¨å®žä¾‹çš„parse æ–¹æ³•ï¼Œå°†è¿”å›žçš„ç»“æžœè§£æžæˆé¢„æœŸçš„JSONæ•°æ®ç»“æž„ã€‚
print(parser.parse(output))
```



## LCELè¯­æ³•è§£æžï¼šåŸºç¡€è¯­æ³•å’ŒæŽ¥å£

LCEL æ˜¯åŸºäºŽLangChainæ¡†æž¶å¼€å‘çš„é¢†åŸŸç‰¹å®šè¯­è¨€(Domain Specifi Language,DSL)ã€‚LCEL æ—¨åœ¨æä¾›ç§ç®€æ´ä¸”å¯Œæœ‰è¡¨çŽ° åŠ›çš„æ–¹å¼æ¥å®š ä¹‰å¤æ‚çš„å¤§è¯­è¨€æ¨¡åž‹å¤„ç†ç®¡é“å’Œå·¥ä½œæµç¨‹ã€‚å®ƒå…è®¸ç”¨æˆ·ä»¥ç»“æž„åŒ–å’Œæ¨¡èŒåŒ–çš„æ–¹å¼å®šä¹‰æ“ä½œé“¾ï¼ŒåŒ…æ‹¬æ•°æ®è½¬æ¢ã€æ¨¡åž‹è°ƒç”¨å’Œè¾“å‡ºè§£æžã€‚

LCELä¸ºæž„å»ºå’Œç¼–æŽ’è¯­è¨€æ¨¡åž‹åº”ç”¨ç¨‹åºæä¾›äº†é«˜çº§æŠ½è±¡ï¼Œä½¿å¼€å‘å’Œç»´æŠ¤å¤æ‚çš„å¤§è¯­è¨€æ¨¡åž‹å¤„ç†ç®¡é“å˜å¾—æ›´åŠ å®¹æ˜“ã€‚LCELçš„åŸºæœ¬è¯­æ³•æ˜¯é€šè¿‡`|`ç®¡é“ç¬¦å·å°†ä¸€äº›ç¬¦åˆ Runnable åè®®çš„å¯¹è±¡( ç®€ç§°ä¸ºRunnableå¯¹è±¡)ä¸²è”èµ·æ¥ã€‚Runnableåè®®æ˜¯ä¸€ä¸ªæ ‡å‡†æŽ¥å£ï¼Œç”±LCELä¸²è”èµ·æ¥çš„Runnableå¯¹è±¡å¯ä»¥è®©å¼€å‘è€…ä»¬è½»æ¾åœ°æž„å»ºè‡ªå®šä¹‰è°ƒç”¨é“¾å¹¶ä»¥æ ‡å‡†æ–¹å¼è°ƒç”¨å®ƒä»¬ã€‚

### Runnable å¯¹è±¡çš„æ ‡å‡†æŽ¥å£

åœ¨Python SDKä¸­ï¼ŒRunnable å¯¹è±¡å®šä¹‰äº†ä¸€ç³»åˆ—æ ‡å‡†çš„æ“ä½œæŽ¥å£ï¼Œå…·ä½“å¦‚ä¸‹ã€‚

1. invoke/ainvoke: å°†å•ä¸ªè¾“å…¥è½¬æ¢ä¸ºè¾“å‡ºã€‚
2. batch/abatch: æœ‰æ•ˆåœ°å°†6ä¸ªè¾“å…¥è½¬æ¢ä¸ºè¾“å‡ºã€‚
3. stream/astream: åœ¨ç”Ÿæˆå•ä¸ªè¾“å…¥æ—¶æµå¼è¾“å‡ºã€‚
4. astream_log:é™¤äº†æœ€ç»ˆå“åº”ï¼Œè¿˜ä¼šæµå¼è¾“å‡ºä¸­é—´æ­¥éª¤çš„æ‰§è¡Œç»“æžœã€‚

å…¶ä¸­å¸¦æœ‰aå‰ç¼€çš„æŽ¥å£æ˜¯å¼‚æ­¥çš„(è¡¨ç¤ºasync)ï¼Œåœ¨é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒä»¬ä½¿ç”¨asyncioçš„çº¿ç¨‹æ± æ‰§è¡ŒåŒæ­¥å¯¹åº”é¡¹ï¼›åœ¨JS SDKä¸­ï¼Œç”±äºŽæ‰€æœ‰æŽ¥å£éƒ½æ˜¯å¼‚æ­¥çš„ï¼Œæ‰€ä»¥åªä¿ç•™invokeã€batchã€streamå’Œstreamlogè¿™4ä¸ªæŽ¥å£ã€‚æ‰€æœ‰æŽ¥å£éƒ½æŽ¥æ”¶å¯é€‰çš„é…ç½®å‚æ•°ï¼Œè¿™äº›å‚æ•°å¯ç”¨äºŽé…ç½®æ‰§è¡Œã€æ·»åŠ æ ‡ç­¾å’Œå…ƒæ•°æ®ï¼Œä»¥è¿›è¡Œè·Ÿè¸ªå’Œè°ƒè¯•ã€‚

### Runnableå¯¹è±¡çš„è¾“å…¥å’Œè¾“å‡ºç±»åž‹

| Runnableå¯¹è±¡ | è¾“å…¥ç±»åž‹                          | è¾“å‡ºç±»åž‹           |
| ------------ | --------------------------------- | ------------------ |
| Prompt       | å­—å…¸ç±»åž‹                          | PromptValue å¯¹è±¡   |
| LLM          | å•ä¸ªå­—ç¬¦ä¸²                        | å•ä¸ªå­—ç¬¦ä¸²         |
| ChatModel    | ä¸€ç»„ChatMessage æˆ–ä¸€ä¸ªPromptValue | ChatMessageå¯¹è±¡    |
| OutputParser | LLMæˆ–ChatModelçš„è¾“å‡ºç±»åž‹          | è§£æžå™¨å„è‡ªå®šä¹‰     |
| Retriever    | å•ä¸ªå­—ç¬¦ä¸²                        | ä¸€ç»„ Document å¯¹è±¡ |
| Tool         | å·¥å…·å„è‡ªå®šä¹‰                      | å·¥å…·å„è‡ªå®šä¹‰       |

## Runnable Sequence çš„åŸºåº§ï¼šModel IO ä¸‰å…ƒç»„å¯¹è±¡

**Runnable Sequence**æ˜¯LangChainä¸­å¦ä¸€ä¸ªé‡è¦æ¦‚å¿µï¼Œå¯ä»¥å°†å®ƒçœ‹æˆ**ç”± LCELæž„å»ºçš„è°ƒç”¨é“¾çš„å®žé™…è½½ä½“ï¼Œå®ƒæè¿°äº†å¤šä¸ª Runnable å¯¹è±¡ç»„åˆæˆçš„é“¾å¼è°ƒç”¨çš„å…·ä½“å†…å®¹ã€‚**

å‰æ–‡ä¸­æåˆ°ï¼ŒRunnable å¯¹è±¡è¡¨ç¤ºä¸€ä¸ªå¯è°ƒç”¨çš„å‡½æ•°æˆ–æ“ä½œå•å…ƒã€‚ä¸åŒçš„Runnable å¯¹è±¡çš„è¾“å…¥å’Œè¾“å‡ºå„å¼‚ï¼Œéœ€è¦æŠŠå‰ä¸€ä¸ªRunnable å¯¹è±¡çš„è¾“å‡ºä½œä¸ºåŽä¸€ä¸ªRunnable å¯¹è±¡çš„è¾“å…¥ï¼Œæ‰èƒ½æŠŠå®ƒä»¬æœ‰æœºä¸²è”èµ·æ¥ã€‚è¦å®žçŽ°ä¸åŒ Runnable å¯¹è±¡ä¹‹é—´çš„ä¸²è”ï¼Œæœ€ç®€å•å’Œæœ€åŸºç¡€çš„æ–¹å¼å°±æ˜¯é€šè¿‡ Model I/O ä¸‰å…ƒç»„ã€‚

1. Promptæ¨¡å—å¯ä»¥å‡†å¤‡ä¸åŒçš„æç¤ºè¯ä½œä¸º Runnable å¯¹è±¡çš„è¾“å…¥ã€‚
2. Modelæ¨¡å—æä¾›å¤§è¯­è¨€æ¨¡åž‹æŽ¥å£ï¼Œå®žçŽ°Runnable å¯¹è±¡çš„ä¸»è¦é€»è¾‘ã€‚
3. Output Parseræ¨¡å—å¯ä»¥æŠŠå‰ä¸€ä¸ªå¯¹è±¡çš„æ¨¡åž‹è¾“å‡ºè½¬æ¢æˆåŽä¸€ä¸ªå¯¹è±¡çš„ç»“æž„åŒ–è¾“å…¥ã€‚

**é€šè¿‡ Mode lO ä¸‰å…ƒç»„çš„æ”¯æŒï¼Œæˆ‘ä»¬å¯ä»¥è‡ªç”±ç»„åˆ Prompt æ¨¡å—ã€Model æ¨¡å—Output Parser æ¨¡å—ï¼Œä»¥æž„å»ºå‡ºä¸€ä¸ªæœ€åŸºç¡€çš„ Runnable Sequenceã€‚**

ä¹‹å‰æˆ‘ä»¬å·²ç»å±•ç¤ºè¿‡ä¸€ä¸ª Promptã€Modelã€Output Parser ä¸‰ä¸ªæ¨¡å—é€šè¿‡ LCELæž„å»º Runnable Sequence çš„ç¤ºä¾‹ï¼Œä¸‹é¢å±•ç¤ºä¸€ä¸ª Prompt æ¨¡å—å’Œ Model æ¨¡å—æž„å»ºæœ€å°è°ƒç”¨é“¾çš„ç¤ºä¾‹ã€‚

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.chat_models import ChatOllama

prompt = ChatPromptTemplate.from_template("è¯·ç¼–å†™ä¸€ç¯‡å…³äºŽ{topic}çš„ä¸­æ–‡å°æ•…äº‹ï¼Œä¸è¶…è¿‡100å­—")
model = ChatOllama(model="qwen:32b")

chain = prompt | model
result = chain.invoke({"topic": "å¥¥ç‰¹æ›¼vså­™æ‚Ÿç©º"}).content
print(result)
# åœ¨ä¸€ä¸ªå¹³è¡Œå®‡å®™ï¼Œå¥¥ç‰¹æ›¼ä¸Žå­™æ‚Ÿç©ºç›¸é‡ã€‚ä»–ä»¬å†³å®šä»¥å‹è°Šèµ›çš„æ–¹å¼ä¸€è¾ƒé«˜ä¸‹ã€‚å¥¥ç‰¹æ›¼ç”¨ä»–çš„å…‰æŸä¸Žå­™æ‚Ÿç©ºçš„æ°”åŠŸæ³¢å¯¹å³™ï¼Œå­™æ‚Ÿç©ºåˆ™ä»¥é‡‘ç®æ£’å’Œèº«æ³•åå‡»ã€‚æœ€ç»ˆï¼Œæ¯”èµ›æ— åˆ†èƒœè´Ÿï¼Œä»–ä»¬æ„è¯†åˆ°ï¼ŒçœŸæ­£çš„åŠ›é‡æ˜¯å‹æƒ…ä¸Žåˆä½œã€‚ä»Žæ­¤ï¼Œå¥¥ç‰¹æ›¼å’Œå­™æ‚Ÿç©ºæˆä¸ºäº†è·¨è¶Šå®‡å®™çš„æœ‹å‹ã€‚
```

***è¿™ç§ç”± Model I/O ä¸‰å…ƒç»„ä¸²è”çš„ Runnable Sequence éžå¸¸åŸºç¡€ï¼Œä½†å®ƒæä¾›äº†æžä¸ºå¹¿æ³›çš„è¯­è¨€å¤„ç†èƒ½åŠ›ã€‚æˆ‘ä»¬å¯ä»¥æ’å…¥å„ç§è‡ªå®šä¹‰çš„ Runnable å¯¹è±¡æ¥å®Œæˆå¤æ‚ä»»åŠ¡ï¼Œæ¯”å¦‚å¤šè½®å¯¹è¯ã€çŸ¥è¯†åº“æŸ¥è¯¢ç­‰ã€‚***

# å¤šåª’ä½“èµ„æºçš„æ‘˜è¦å®žæˆ˜

LangChainåœ¨æ–‡æ¡£å¤„ç†æ–¹é¢æä¾›äº†å¤šç§å¤„ç†ç­–ç•¥ï¼Œå®ƒä»¬å¯¹äºŽæ€»ç»“æ–‡æ¡£ã€å›žç­”æ–‡æ¡£é—®é¢˜ã€ä»Žæ–‡æ¡£ä¸­æå–ä¿¡æ¯ç­‰å¾ˆæœ‰ç”¨

## Stuffç­–ç•¥ï¼šç›´æŽ¥åˆå¹¶

- å…ˆå°†æ‰€æœ‰æ–‡æ¡£ç›´æŽ¥æ‹¼åœ¨ä¸€èµ·ï¼Œç»„æˆä¸€å¤§æ®µæ–‡æœ¬ï¼Œç„¶åŽå°†å…¶ä¸Žé—®é¢˜ä¸€èµ·è¾“å…¥é—®ç­”æ¨¡åž‹ï¼Œç”Ÿæˆç­”æ¡ˆ

![image-20240515101236015](./LangChainæ•™ç¨‹.assets/image-20240515101236015.png)

```python
from langchain_core.prompts import PromptTemplate, format_document
from langchain_core.output_parsers import StrOutputParser
from langchain_community.chat_models import ChatOllama
from langchain_community.document_loaders import ArxivLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# åŠ è½½ arXiv ä¸Šçš„è®ºæ–‡ã€ŠReAct: Synergizing Reasoning and Acting in Language Modelsã€‹
loader = ArxivLoader(query="2210.03629", load_max_docs=1)
docs = loader.load()
print(docs[0].metadata)

# æŠŠæ–‡æœ¬åˆ†å‰²æˆ 500 å­—ä¸€ç»„çš„åˆ‡ç‰‡
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 500,
    chunk_overlap = 0
)
chunks = text_splitter.split_documents(docs)

# æž„å»º Stuff å½¢æ€ï¼ˆå³æ–‡æœ¬ç›´æŽ¥æ‹¼åˆï¼‰çš„æ€»ç»“é“¾
doc_prompt = PromptTemplate.from_template("{page_content}")
chain = (
    {
        "content": lambda docs: "\n\n".join(
            format_document(doc, doc_prompt) for doc in docs
        )
    }
    | PromptTemplate.from_template("ç”¨ä¸­æ–‡æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼Œä¸éœ€è¦äººç‰©ä»‹ç»ï¼Œå­—æ•°æŽ§åˆ¶åœ¨ 50 å­—ä»¥å†…ï¼š\n\n{content}")
    | ChatOllama(model="llama2-chinese:13b")
    | StrOutputParser()
)
# ç”±äºŽè®ºæ–‡å¾ˆé•¿ï¼Œæˆ‘ä»¬åªé€‰å–å‰ 2000 å­—ä½œä¸ºè¾“å…¥å¹¶è°ƒç”¨æ€»ç»“é“¾
chain.invoke(chunks[:4])
# '\nREACTæ˜¯ä¸€ç§ç ”ç©¶è¯­è¨€æ¨¡åž‹ä¸­çš„åˆç†å’Œè¡ŒåŠ¨ä¹‹é—´åè°ƒçš„æŠ€æœ¯ã€‚åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰ä¸­ï¼Œç ”ç©¶è®ºæ–­å’Œè¡ŒåŠ¨çš„èƒ½åŠ›ä¸€ç›´è¢«è§†ä¸ºä¸åŒçš„è¯é¢˜ã€‚æœ¬æ–‡è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨LLMæ¥ç”Ÿæˆè®ºæ–­è·¯å¾„å’Œä»»åŠ¡ç‰¹å®šçš„è¡ŒåŠ¨ã€‚è¿™æ ·åšå¯ä»¥æ›´å¥½åœ°åˆ©ç”¨ä¸¤ä¸ªæ–¹é¢çš„èƒ½åŠ›ï¼šè®ºæ–­è·¯å¾„å¸®åŠ©æ¨¡åž‹æŽ¨å¯¼ã€ä¿®æ”¹å’Œæ›´æ–°è¡ŒåŠ¨è®¡åˆ’ï¼Œå¹¶å¤„ç†ä¾‹å¤–æƒ…å†µï¼›è€Œè¡ŒåŠ¨ä½¿å¾—æ¨¡åž‹ä¸ŽçŸ¥è¯†åº“æˆ–çŽ¯å¢ƒè¿›è¡Œäº¤äº’å’ŒèŽ·å–æ›´å¤šä¿¡æ¯ã€‚æˆ‘ä»¬åº”ç”¨äº†ReActæŠ€æœ¯ï¼Œåœ¨å„ç§è¯­è¨€ç†è§£å’Œäº¤äº’å¼å†³ç­–ä»»åŠ¡ä¸­éƒ½æœ‰å‡ºè‰²è¡¨çŽ°ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨HotpotQAå’ŒFeveré—®é¢˜ä¸Šï¼ŒReActè¶…è¿‡äº†åŸºçº¿æ¨¡åž‹çš„æ™®éé—®é¢˜ï¼ŒåŒ…æ‹¬è¿·æ€å’Œé”™ä½ç†è§£ã€‚æ­¤å¤–ï¼Œåœ¨ä¸¤ä¸ªäº¤äº’å¼å†³ç­–ä»»åŠ¡ï¼ˆALFWorldå’ŒWebShopï¼‰ä¸­ï¼ŒReActæ¯”ä»¥ä¸Šä¸¤ç§æ–¹æ³•æ›´é«˜çš„æˆåŠŸçŽ‡è¾¾åˆ°äº†34%å’Œ10%ã€‚è¿™äº›è®ºæ–­è·¯å¾„æ›´åŠ å¯è¯»æ€§å¼ºå¤§ï¼Œä½¿å¾—äººä»¬èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£æ¨¡åž‹çš„ä»»åŠ¡è§£é‡Šæ–¹å¼ã€‚\n'
```



## MapReduceç­–ç•¥ï¼šåˆ†è€Œæ²»ä¹‹

- **æ›´é€‚ç”¨äºŽå¤§è§„æ¨¡æ–‡æ¡£çš„é—®ç­”åœºæ™¯ï¼Œå½“æ–‡æ¡£é‡æˆåƒä¸Šä¸‡æ—¶ï¼Œå®ƒå¯ä»¥å‘æŒ¥ç®—æ³•è®¾è®¡çš„ä¼˜åŠ¿**
- ä½¿ç”¨äº†å¤§æ•°æ®ä¸­å¸¸è§çš„MapReduceæ¨¡å¼ï¼š
  - Mapé˜¶æ®µï¼šæ¯ä¸ªæ–‡æ¡£å•ç‹¬è¿›è¡Œå¤„ç†ï¼Œç”Ÿæˆä¸€ä¸ªé’ˆå¯¹é—®é¢˜çš„ä¸­é—´å›žç­”ã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥è¢«çœ‹ä½œæ˜¯ä¸€ä¸ªâ€œå¾®å°é—®ç­”â€ï¼Œå¯¹æ¯ä¸ªæ–‡æ¡£è¿›è¡Œå•ç‹¬æ±‡æ€»ã€‚
  - Reduceé˜¶æ®µï¼šå°†æ‰€æœ‰æ–‡æ¡£çš„ä¸­é—´å›žç­”ç»Ÿä¸€æ±‡æ€»åˆ°ä¸€ä¸ªæ–‡æ¡£ä¸­ã€‚ä¸ŽåŽŸå§‹é—®é¢˜ä¸€èµ·ä½œä¸ºæ–°çš„æç¤ºè¯ä¸Šä¸‹æ–‡å†…å®¹ï¼Œè¾“å…¥é—®ç­”æ¨¡åž‹å¹¶ç”Ÿæˆæœ€ç»ˆå›žç­”ã€‚
- MapReduce ç­–ç•¥çš„ä¼˜åŠ¿å¦‚ä¸‹ï¼š
  1. å¯ä»¥åŸºäºŽæ¯ä¸ªæ–‡æ¡£çš„ç›¸å…³æ€§å¯¹å…¶è¿›è¡Œä¸åŒç¨‹åº¦çš„æ±‡æ€»ï¼Œè€Œä¸ä¼šç®€å•æ‹¼æŽ¥
  2. åˆ†é˜¶æ®µé€æ­¥æŽ¨ç†çš„è¿‡ç¨‹æ›´è´´è¿‘äººç±»å¤„ç†å¤§è§„æ¨¡æ–‡æ¡£çš„æ€ç»´æ¨¡å¼
  3. æ”¯æŒå¹¶è¡Œè®¡ç®—å¯¹äºŽå¤§è§„æ¨¡æ–‡æ¡£åœºæ™¯å…·æœ‰å¾ˆå¼ºçš„å¯æ‰©å±•æ€§

![image-20240515101330281](./LangChainæ•™ç¨‹.assets/image-20240515101330281.png)

```python
from functools import partial

from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import PromptTemplate, format_document
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import ArxivLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# åŠ è½½ arXiv ä¸Šçš„è®ºæ–‡ã€ŠReAct: Synergizing Reasoning and Acting in Language Modelsã€‹
loader = ArxivLoader(query="2210.03629", load_max_docs=1)
docs = loader.load()

# æŠŠæ–‡æœ¬åˆ†å‰²æˆ 500 å­—ä¸€ç»„çš„åˆ‡ç‰‡
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 500,
    chunk_overlap = 50
)
chunks = text_splitter.split_documents(docs)

llm = ChatOllama(model="llama2-chinese:13b")

# æž„å»ºå·¥å…·å‡½æ•°ï¼šå°† Document è½¬æ¢æˆå­—ç¬¦ä¸²
document_prompt = PromptTemplate.from_template("{page_content}")
partial_format_document = partial(format_document, prompt=document_prompt)

# æž„å»º Map é“¾ï¼šå¯¹æ¯ä¸ªæ–‡æ¡£éƒ½å…ˆè¿›è¡Œä¸€è½®æ€»ç»“
map_chain = (
    {"context": partial_format_document}
    | PromptTemplate.from_template("Summarize this content:\n\n{context}")
    | llm
    | StrOutputParser()
)

# æž„å»º Reduce é“¾ï¼šåˆå¹¶ä¹‹å‰çš„æ‰€æœ‰æ€»ç»“å†…å®¹
reduce_chain = (
    {"context": lambda strs: "\n\n".join(strs) }
    | PromptTemplate.from_template("Combine these summaries:\n\n{context}")
    | llm
    | StrOutputParser()
)

# æŠŠä¸¤ä¸ªé“¾åˆå¹¶æˆ MapReduce é“¾
map_reduce = map_chain.map() | reduce_chain
map_reduce.invoke(chunks[:4], config={"max_concurrency": 5})
# 'This paper presents REACT, an architecture that combines reasoning and acting capabilities into large language models, enabling more synergy between the two and better handling of exceptions and unexpected events. The authors investigate using LLMs to generate reasoning traces and task-specific actions in an interleaved manner. This approach has been shown to outperform existing state-of-the-art baselines in tasks like question answering and fact verification, with a simple Wikipedia API providing information and generating more interpretable task-solving trajectories than previous methods. The authors provide a detailed explanation of how ReAct works and why it achieves strong performance.\n'
```



## Refineç­–ç•¥ï¼šå¾ªåºè¿­ä»£

- Refine ç­–ç•¥ä¸Ž MapReduce ç­–ç•¥ç±»ä¼¼ï¼Œä¹Ÿåˆ†å¤šè½®é€æ­¥è¿›è¡ŒæŽ¨ç†ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ä½†æ˜¯ï¼Œå®ƒæ¯ä¸€è½®çš„è¾“å…¥éƒ½åªåŒ…å«ä¸€ä¸ªæ–‡æ¡£ï¼Œä»¥åŠä¹‹å‰è½®æ¬¡çš„ä¸­é—´å›žç­”ã€‚

![image-20240515101339581](./LangChainæ•™ç¨‹.assets/image-20240515101339581.png)

- å…·ä½“æ¥è¯´ï¼ŒRefneç­–ç•¥çš„å¤„ç†æµç¨‹å¦‚ä¸‹ï¼š
  1. åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„ Context ä¸Šä¸‹æ–‡å˜é‡ã€‚
  2. éåŽ†æ¯ä¸ªæ–‡æ¡£ï¼Œå°†å…¶ä¸ŽContextæ‹¼æŽ¥ä½œä¸ºæç¤ºè¯çš„ä¸Šä¸‹æ–‡éƒ¨åˆ†è¾“å…¥é—®ç­”æ¨¡åž‹ã€‚
  3. å¤§è¯­è¨€æ¨¡åž‹ç”Ÿæˆçš„å›žç­”ä½œä¸ºæ–°çš„Contextï¼Œä¾›ä¸‹ä¸€è½®ä½¿ç”¨
  4. é‡å¤æ­¥éª¤2å’Œæ­¥éª¤3ï¼Œç›´åˆ°å®Œæˆæ‰€æœ‰æ–‡æ¡£çš„å¤„ç†ã€‚
  5. å¾—åˆ°çš„æœ€åŽä¸€ä¸ª Context å³ä¸ºæœ€ç»ˆå›žç­”ã€‚
- Refine ç­–ç•¥çš„ä¸»è¦ä¼˜åŠ¿å¦‚ä¸‹ï¼š
  1. æ¯æ¬¡åªéœ€è¦é’ˆå¯¹ä¸€ä¸ªæ–‡æ¡£ç”Ÿæˆå›žç­”ï¼Œé¿å…äº†è¿‡é•¿çš„ Context.
  2. å›žç­”æ˜¯é€æ­¥æŽ¨ç†å’Œå®Œå–„çš„ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§å¡žå…¥æ‰€æœ‰ä¿¡æ¯ã€‚
  3. å¯ä»¥è‡ªå®šä¹‰æ¯è½®çš„æç¤ºè¯æ¨¡æ ¡å®žçŽ°æ›´ç²¾ç»†çš„æŽ§åˆ¶ã€‚
- ä½†æ˜¯ Refine ç­–ç•¥ä¹Ÿå­˜åœ¨ä»¥ä¸‹é™åˆ¶ã€‚
  1. æ–‡æ¡£çš„é¡ºåºå¯¹ç»“æžœæœ‰å¾ˆå¤§å½±å“ï¼Œéœ€è¦æ™ºèƒ½æŽ’åºï¼Œ
  2. è®¡ç®—é‡ä¸Žæ–‡æ¡£é‡çº¿æ€§ç›¸å…³ï¼Œæ—¶é—´æˆæœ¬é«˜ã€‚
  3. å¾€å¾€éœ€è¦æ›´å¤šçš„è½®æ¬¡æ‰èƒ½æ”¶æ•›ï¼Œæ•ˆçŽ‡ä¸å¦‚MapReduce ç­–ç•¥é«˜
- å› æ­¤ï¼ŒRefneç­–ç•¥å¯¹**æç¤ºè¯è®¾è®¡**å’Œ**æ–‡æ¡£æŽ’åºæŠ€å·§**çš„è¦æ±‚æ›´é«˜ï¼Œä½†å¯ä»¥äº§ç”Ÿæ›´æµç•…ã€è¿žè´¯çš„å›žç­”ã€‚å®ƒæ›´é€‚åˆäº¤å‰å…³è”æ€§å¼ºçš„æ–‡æ¡£é›†ï¼Œåœ¨æ–‡æ¡£é‡é€‚ä¸­æ—¶æ•ˆæžœæœ€ä½³ä¸‹é¢æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹å¯¹åº”çš„LCELå®žçŽ°ï¼Œç»§ç»­ä½¿ç”¨ReActè®ºæ–‡æ€»ç»“åœºæ™¯ï¼Œå¯ä»¥ç€é‡å…³æ³¨ Refine ç­–ç•¥ç”¨åˆ°çš„ä¸¤ç»„ä¸åŒçš„æç¤ºè¯ï¼Œä»¥åŠå¾ªçŽ¯è¿‡ç¨‹çš„æž„å»ºæ–¹å¼ã€‚

# é¢å‘æ–‡æ¡£çš„å¯¹è¯æœºå™¨äºº

> åŸºäºŽæ–‡æ¡£å†…å®¹æ¥å›žç­”é—®é¢˜

## RAGå·¥ä½œåŽŸç†

æ·±å…¥äº†è§£ RAG çš„å·¥ä½œåŽŸç†ï¼Œæˆ‘ä»¬éœ€è¦é€æ­¥è§£æžå…¶ä¸­çš„æ¯ä¸€ä¸ªæ­¥éª¤ã€‚

### 1. æž„å»ºçŸ¥è¯†åº“ç´¢å¼•

è¿™ä¸€æ­¥çš„ç›®æ ‡æ˜¯***å°†æˆ‘ä»¬å‡†å¤‡çš„ç”¨æ¥è®­ç»ƒå¯¹è¯æœºå™¨äººçš„ã€æ–‡æ¡£æˆ–ç½‘ç«™çŸ¥è¯†åº“ã€‘è½¬æ¢ä¸ºã€å¯ä»¥å¿«é€Ÿæœç´¢çš„æ ¼å¼ã€‘***ã€‚å…·ä½“æ¥è¯´ï¼Œè¦å®Œæˆä»¥ä¸‹å·¥ä½œï¼š

1. ä½¿ç”¨æ–‡æ¡£åŠ è½½å™¨**åŠ è½½çŸ¥è¯†åº“**ï¼šæ–‡æ¡£åŠ è½½å™¨è´Ÿè´£æŠ“å–æ–‡æ¡£ï¼Œæå–æ–‡æ¡£çš„åŽŸå§‹æ–‡æœ¬ã€‚
2. ä½¿ç”¨**æ–‡æœ¬åˆ†å‰²**å™¨å¯¹æ–‡æ¡£è¿›è¡Œåˆ†å‰²ï¼šå¯¹ä¸€ä¸ªé•¿æ–‡æ¡£æ¥è¯´ï¼Œå¯èƒ½å…¶ä¸­åªæœ‰å‡ æ®µæ–‡æœ¬å’Œç”¨æˆ·çš„é—®é¢˜ç›¸å…³ã€‚æ‰€ä»¥è¿™é‡Œè¦å°†æ–‡æ¡£åˆ†å‰²æˆè¯­ä¹‰å®Œæ•´çš„ç‰‡æ®µ(å½“ç„¶ï¼Œå°†æ–‡æ¡£åˆ†å‰²æˆå¤šå°‘ä¸ªç‰‡æ®µä¹Ÿæ˜¯éœ€è¦é€šè¿‡å®žé™…è°ƒè¯•çš„ï¼Œä¸æ˜¯ä¸€ä¸ªå›ºå®šçš„ã€å¯ç›´æŽ¥è®¡ç®—çš„æ•°å€¼)ã€‚
3. ä½¿ç”¨ Embedding æ¨¡åž‹ç”Ÿæˆ**å‘é‡è¡¨ç¤º**ï¼šä½¿ç”¨é¢„è®­ç»ƒå¥½çš„Embeddingæ¨¡åž‹ä¸ºæ¯ä¸€ä¸ªæ–‡æœ¬ç‰‡æ®µç”Ÿæˆä¸€ä¸ªå›ºå®šé•¿åº¦çš„è¿žç»­å‘é‡ï¼Œè¿™æ˜¯å­˜å…¥å‘é‡å­˜å‚¨çš„åŸºç¡€
4. **æž„å»ºå‘é‡ç´¢å¼•**ï¼šå°†æ‰€æœ‰æ–‡æœ¬ç‰‡æ®µçš„å‘é‡è¡¨ç¤ºå’ŒåŽŸæ–‡å­˜å‚¨åœ¨å‘é‡æœç´¢å¼•æ“Žä¸­ï¼Œæ¯”å¦‚FAISSã€Pineconeã€Milvusã€Chromaç­‰ã€‚

å®Œæˆè¿™ä¸€æ­¥åŽï¼ŒçŸ¥è¯†åº“å°±å˜æˆäº†ä¸€ä¸ªå¯æœç´¢çš„å‘é‡æ•°æ®åº“ã€‚

### 2. åŸºäºŽçŸ¥è¯†åº“è¿›è¡Œæ£€ç´¢

å½“æŽ¥æ”¶åˆ°ç”¨æˆ·çš„é—®é¢˜æ—¶ï¼ŒRAG æŒ‰ä»¥ä¸‹æ­¥éª¤è¿›è¡Œç›¸å…³å†…å®¹çš„æ£€ç´¢ï¼š

1. ä½¿ç”¨ç›¸åŒçš„Embeddingæ¨¡åž‹å°†**å‘é¢˜è½¬æ¢**ä¸ºå‘é‡è¡¨ç¤ºã€‚**ã€æ³¨æ„ã€‘ä¸€å®šè¦ä½¿ç”¨ç›¸åŒçš„ Embedding æ¨¡åž‹**ï¼Œä¸åŒ Embedding æ¨¡åž‹çš„ç®—æ³•å’Œå‘é‡ç©ºé—´ç»´åº¦ä¸åŒã€‚
2. åœ¨å‘é‡ç´¢å¼•ä¸­**æ‰¾å‡ºä¸Žé—®é¢˜å‘é‡æœ€ç›¸ä¼¼çš„Nä¸ªæ–‡æœ¬å‘é‡**ã€‚æ³¨æ„è¿™ä¸€æ­¥ä½¿ç”¨çš„æ˜¯å‘é‡å­˜å‚¨çš„**ç›¸ä¼¼åº¦åŒ¹é…ã€æŸ¥è¯¢èƒ½åŠ›**ï¼Œå¸¸è§è¯¯åŒºæ˜¯Embeddingæ¨¡åž‹å…·æœ‰æŸ¥è¯¢èƒ½åŠ›ï¼Œå®žé™…ä¸Š **Embedding æ¨¡åž‹åªè´Ÿè´£ç”Ÿæˆæ–‡æœ¬å‘é‡è¡¨ç¤ºçš„æ•°æ®**ã€‚
3. **è¿”å›žå¯¹åº”çš„åŽŸæ–‡æ–‡æœ¬**ä½œä¸ºç›¸å…³å†…å®¹ã€‚æ³¨æ„åŽŸæ–‡æ–‡æœ¬æ˜¯éšæ–‡æœ¬å‘é‡ä¸€èµ·å­˜å…¥å‘é‡å­˜å‚¨çš„ï¼Œé€šå¸¸ä¸€èµ·è¢«å­˜å…¥çš„è¿˜å¯ä»¥æœ‰ä¸€äº›==**æ–‡æ¡£çš„å…ƒæ•°æ®**==ã€‚å®ƒä»¬å¯ä»¥éšå‘é‡æŸ¥è¯¢çš„ç»“æžœä¸€èµ·è¢«å–å‡ºã€‚

é€šè¿‡å¿«é€Ÿçš„**å‘é‡ç›¸ä¼¼åº¦åŒ¹é…å’ŒæŸ¥è¯¢**ï¼Œæˆ‘ä»¬å¯ä»¥ä»Žæµ·é‡æ–‡æœ¬ä¸­å®žæ—¶å®šä½å‡ºä¸Žç”¨æˆ·é—®é¢˜æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚

### 3. åŸºäºŽæ£€ç´¢å†…å®¹å¢žå¼ºç”Ÿæˆ

**æ‹¿åˆ°ç›¸å…³å†…å®¹ä¹‹åŽï¼Œæˆ‘ä»¬å°†å…¶ä¸ŽåŽŸé—®é¢˜ä¸€èµ·è¾“é€ç»™å¤§è¯­è¨€æ¨¡åž‹**ï¼Œè¾…åŠ©å…¶ç”Ÿæˆç­”æ¡ˆï¼š

1. ä½¿ç”¨**ç³»ç»Ÿæç¤º**ä½œä¸ºå‰ç¼€æŒ‡ç¤ºå¤§è¯­è¨€æ¨¡åž‹æˆ‘ä»¬æä¾›äº†ç›¸å…³å†…å®¹ï¼Œè¦ç»¼åˆè€ƒè™‘åŽè¿›è¡Œå›žç­”ã€‚
2. å°†**ç›¸å…³å†…å®¹**å’Œ**é—®é¢˜**æŒ‰è‡ªå®šä¹‰çš„æ ¼å¼è¿›è¡Œ**æ‹¼æŽ¥**ã€‚å¯ä»¥å°†ç›¸å…³å†…å®¹**æ ‡æ³¨**ä¸º**æ¥æº**ï¼Œä»¥ç¤ºåŒºåˆ†ã€‚
3. å°†ç»„è£…å¥½çš„æ–‡æœ¬ä½œä¸ºæç¤ºè¯**è¾“å…¥å¤§è¯­è¨€æ¨¡åž‹ï¼Œç”Ÿæˆ**å›žå¤

å¢žå¼ºç”Ÿæˆæ˜¯RAGçš„æœ€åŽä¸€æ­¥ï¼Œä¹Ÿæ˜¯æ•´ä¸ªæµç¨‹çš„ç›®æ ‡å’Œç„¦ç‚¹ã€‚å¤§è¯­è¨€æ¨¡åž‹å¯ä»¥å……åˆ†åˆ©ç”¨æä¾›çš„å¤–éƒ¨ä¿¡æ¯ï¼Œç»™å‡ºé’ˆå¯¹æ€§å¼ºä¸”è¯­ä¹‰è¿žè´¯çš„å›žç­”ã€‚

é€šè¿‡ä¸Šé¢çš„æè¿°ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒRAGä¸ºæž„å»ºç‰¹å®šé¢†åŸŸçš„å¯¹è¯æœºå™¨äººæä¾›äº†æ¸…æ™°ã€é«˜æ•ˆçš„å·¥ä½œæµç¨‹ã€‚å®ƒç»“åˆäº†å‘é‡æœç´¢çš„å¼ºå¤§æ£€ç´¢èƒ½åŠ›å’Œå¤§è¯­è¨€æ¨¡åž‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œä½¿æˆ‘ä»¬åªéœ€è¦ç¼–å†™å°‘é‡ä»£ç å°±å¯ä»¥å®žçŽ°æ˜¾è‘—çš„é—®ç­”å¢žå¼ºæ•ˆæžœã€‚éšç€è¿™ä¸€é¢†åŸŸçš„å¿«é€Ÿå‘å±•ï¼Œæœªæ¥RAGç³»ç»Ÿçš„æ€§èƒ½è¿˜å°†æŒç»­æå‡ã€‚

## RAGæž¶æž„

![5-1](./LangChainæ•™ç¨‹.assets/5-1.png)

## ä»£ç å®žçŽ°

```python
from operator import itemgetter

from langchain_core.prompts import ChatPromptTemplate, PromptTemplate, format_document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores.faiss import FAISS
from langchain_community.document_loaders import ArxivLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Step 1: 
# åŠ è½½ arXiv ä¸Šçš„è®ºæ–‡ã€ŠReAct: Synergizing Reasoning and Acting in Language Modelsã€‹
# load_max_docs=1 è¡¨ç¤ºåªåŠ è½½ç¬¬ä¸€ç¯‡è®ºæ–‡
loader = ArxivLoader(query="2210.03629", load_max_docs=1)
docs = loader.load()
# print(docs[0].metadata)
#{'Published': '2023-03-10', 'Title': 'ReAct: Synergizing Reasoning and Acting in Language Models', 'Authors': 'Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao', 'Summary': 'While large language models (LLMs) have demonstrated impressive capabilities\nacross tasks in language understanding and interactive decision making, their\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.\naction plan generation) have primarily been studied as separate topics. In this\npaper, we explore the use of LLMs to generate both reasoning traces and\ntask-specific actions in an interleaved manner, allowing for greater synergy\nbetween the two: reasoning traces help the model induce, track, and update\naction plans as well as handle exceptions, while actions allow it to interface\nwith external sources, such as knowledge bases or environments, to gather\nadditional information. We apply our approach, named ReAct, to a diverse set of\nlanguage and decision making tasks and demonstrate its effectiveness over\nstate-of-the-art baselines, as well as improved human interpretability and\ntrustworthiness over methods without reasoning or acting components.\nConcretely, on question answering (HotpotQA) and fact verification (Fever),\nReAct overcomes issues of hallucination and error propagation prevalent in\nchain-of-thought reasoning by interacting with a simple Wikipedia API, and\ngenerates human-like task-solving trajectories that are more interpretable than\nbaselines without reasoning traces. On two interactive decision making\nbenchmarks (ALFWorld and WebShop), ReAct outperforms imitation and\nreinforcement learning methods by an absolute success rate of 34% and 10%\nrespectively, while being prompted with only one or two in-context examples.\nProject site with code: https://react-lm.github.io'}


# æŠŠæ–‡æœ¬åˆ†å‰²æˆ 200 å­—ä¸€ç»„çš„åˆ‡ç‰‡,å¹¶é‡å 20ä¸ªå­—ç¬¦,æ–‡æœ¬å—è¶Šå¤§ï¼Œè¶Šå®¹æ˜“åŒ¹é…ï¼Œä½†ä¹Ÿä¼šäº§ç”Ÿæ›´å¤šæ— å…³ä¸Šä¸‹æ–‡
text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)
chunks = text_splitter.split_documents(docs)

# Step 2: 
# åŸºäºŽå‰10ä¸ªæ–‡æœ¬å—æž„å»º FAISS å‘é‡å­˜å‚¨å’Œå¯¹åº”çš„ retriever
# FAISS æ˜¯ä¸€ç§å‘é‡æ•°æ®åº“ï¼Œç”¨äºŽé«˜æ•ˆåœ°æœç´¢å’Œæ£€ç´¢å‘é‡æ•°æ®
# è¿™é‡Œä½¿ç”¨FAISS.from_documentsæ¥å°†æ–‡æ¡£å¯¼å…¥å‘é‡å­˜å‚¨ï¼Œè¯¥æ–¹æ³•å…·æœ‰ã€æ–‡æ¡£åˆ—è¡¨ã€‘å’Œã€è¦ä½¿ç”¨çš„embeddingæ¨¡åž‹ã€‘ä¸¤ä¸ªå‚æ•°
vs = FAISS.from_documents(chunks[:10], OllamaEmbeddings(model="llama2-chinese:13b"))
# vs.similarity_search("What is ReAct")
# ä½¿ç”¨å‘é‡å­˜å‚¨çš„as_retrieveræ–¹æ³•å¯ä»¥ç›´æŽ¥å¾—åˆ°ç»‘å®šè¯¥å‘é‡å­˜å‚¨çš„æ£€ç´¢å™¨å®žä¾‹å¯¹è±¡
retriever = vs.as_retriever()

# Step 3: 
# æž„å»º Document è½¬æ–‡æœ¬æ®µè½çš„å·¥å…·å‡½æ•°
DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template="{page_content}")
# æ£€ç´¢å™¨è¿”å›žçš„ç»“æžœæ˜¯ä¸€ç»„Documentå¯¹è±¡ï¼Œä½†è¾“å…¥ç»™æç¤ºè¯æ¨¡æ¿ä½œä¸ºä¸Šä¸‹æ–‡çš„å†…å®¹éœ€è¦æ˜¯å­—ç¬¦ä¸²ï¼Œ
# æ‰€ä»¥å¿…é¡»ä½¿ç”¨ä¸€ä¸ªè¿™æ ·çš„å·¥å…·å‡½æ•°æ¥å®Œæˆã€æ–‡æ¡£å†…å®¹çš„æå–ã€‘å’Œã€å­—ç¬¦ä¸²åŒ–ã€‘çš„å·¥ä½œ
def _combine_documents(docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator="\n\n"):
    doc_strings = [format_document(doc, document_prompt) for doc in docs]
    return document_separator.join(doc_strings)

# å‡†å¤‡ Model I/O ä¸‰å…ƒç»„
template = """Answer the question based only on the following context:
{context}

Question: {question}
"""
prompt = ChatPromptTemplate.from_template(template)
model = ChatOllama(model="llama2-chinese:13b")

# Step 4: 
# æž„å»º RAG é“¾
chain = (
    # å‡†å¤‡ä¸Šä¸‹æ–‡ï¼Œä»Žæ–‡æ¡£ä¸­æ£€ç´¢å‡ºå’Œç”¨æˆ·é—®é¢˜æœ€ç›¸å…³çš„å†…å®¹ï¼ŒæŠŠå®ƒæŠ½å–å‡ºæ¥å¹¶æ‹¼æŽ¥æˆä¸€æ®µå‚è€ƒæ–‡æœ¬ã€‚
    {
        "context": retriever | _combine_documents,
        "question": RunnablePassthrough()
    }
    # åˆ©ç”¨Model IOä¸‰å…ƒç»„å®Œæˆå¯¹ç”¨æˆ·é—®é¢˜çš„å›žç­”
    | prompt
    | model
    | StrOutputParser()
)
chain.invoke("ä»€ä¹ˆæ˜¯ ReActï¼Ÿ")

# 'ReActæ˜¯ä¸€ç§å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰ï¼Œå®ƒå¯ä»¥è¿›è¡Œè¾ƒå¥½çš„æ€ç»´å’Œè¡ŒåŠ¨èƒ½åŠ›ã€‚ ReActé€šè¿‡å¯¹é€»è¾‘å’ŒåŠ¨ä½œä¸¤è€…çš„åŒæ—¶ä¼˜åŒ–æ¥æé«˜å…¶è¡¨çŽ°åº¦ï¼Œå¹¶è¢«åº”ç”¨äºŽè¯­è¨€ç†è§£å’Œäº¤äº’å†³ç­–ç­‰å¤šä¸ªä»»åŠ¡ä¸­ã€‚\n'
```

# è‡ªç„¶è¯­è¨€äº¤æµçš„æœç´¢å¼•æ“Žå®žæˆ˜

```python
from langchain import hub
from langchain_community.llms.openai import OpenAI
from langchain.agents import load_tools 
from langchain.agents import AgentExecutor
from langchain.agents.output_parsers import ReActSingleInputOutputParser
from langchain.agents.format_scratchpad import format_log_to_str
from langchain.tools.render import render_text_description
from langchain_community.chat_models import ChatOllama

# é€šè¿‡ python-dotenv åŠ è½½çŽ¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

# å‡†å¤‡å¤§è¯­è¨€æ¨¡åž‹ï¼šè¿™é‡Œéœ€è¦ OpenAIï¼Œå¯ä»¥æ–¹ä¾¿åœ°æŒ‰éœ€åœæ­¢æŽ¨ç†
llm = OpenAI()
# llm = ChatOllama(model="qwen:32b")
llm_with_stop = llm.bind(stop=["\nObservation"])

# å‡†å¤‡æˆ‘ä»¬çš„å·¥å…·ï¼šè¿™é‡Œç”¨åˆ° DuckDuckGo æœç´¢å¼•æ“Žï¼Œå’Œä¸€ä¸ªåŸºäºŽ LLM çš„è®¡ç®—å™¨
tools = load_tools(["ddg-search", "llm-math"], llm=llm)

# å‡†å¤‡æ ¸å¿ƒæç¤ºè¯ï¼šè¿™é‡Œä»Ž LangChain Hub åŠ è½½äº† ReAct æ¨¡å¼çš„æç¤ºè¯ï¼Œå¹¶å¡«å……å·¥å…·çš„æ–‡æœ¬æè¿°
prompt = hub.pull("hwchase17/react")
prompt = prompt.partial(
    tools=render_text_description(tools),
    tool_names=", ".join([t.name for t in tools]),
)

# æž„å»º Agent çš„å·¥ä½œé“¾ï¼šè¿™é‡Œæœ€é‡è¦çš„æ˜¯æŠŠä¸­é—´æ­¥éª¤çš„ç»“æž„è¦ä¿å­˜åˆ°æç¤ºè¯çš„ agent_scratchpad ä¸­
agent = (
    {
        "input": lambda x: x["input"],
        "agent_scratchpad": lambda x: format_log_to_str(x["intermediate_steps"]),
    }
    | prompt
    | llm_with_stop
    | ReActSingleInputOutputParser()
)

# æž„å»º Agent æ‰§è¡Œå™¨ï¼šæ‰§è¡Œå™¨è´Ÿè´£æ‰§è¡Œ Agent å·¥ä½œé“¾ï¼Œç›´è‡³å¾—åˆ°æœ€ç»ˆç­”æ¡ˆï¼ˆçš„æ ‡è¯†ï¼‰å¹¶è¾“å‡ºå›žç­”
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
agent_executor.invoke({"input": "ä»Šå¤©ä¸Šæµ·å’ŒåŒ—äº¬çš„æ°”æ¸©å·®å‡ åº¦ï¼Ÿ(ç”¨ä¸­æ–‡å›žç­”)"})


# > Entering new AgentExecutor chain...
#  é¦–å…ˆï¼Œæˆ‘éœ€è¦äº†è§£ä¸Šæµ·å’ŒåŒ—äº¬çš„å¤©æ°”æƒ…å†µã€‚
# Action: duckduckgo_search
# Action Input: ä¸Šæµ·å¤©æ°”ä»Šæ—¥å¤©æ°”-ä¸Šæµ·å¸‚æ°”è±¡å±€æ˜¯æ‚¨æŸ¥è¯¢ä¸Šæµ·å¸‚å½“å¤©çš„æ°”è±¡çŠ¶å†µã€é¢„è­¦ä¿¡æ¯ã€ç”Ÿæ´»æŒ‡æ•°çš„æœ€ä½³å¹³å°ã€‚æ‚¨å¯ä»¥äº†è§£ä¸Šæµ·å¸‚çš„æ¸©åº¦ã€æ¹¿åº¦ã€é£ŽåŠ›ã€é™æ°´ã€èƒ½è§åº¦ç­‰æ•°æ®ï¼Œä»¥åŠæœªæ¥å‡ å¤©çš„å¤©æ°”è¶‹åŠ¿å’Œç©ºæ°”è´¨é‡çŠ¶å†µã€‚æ‚¨è¿˜å¯ä»¥æµè§ˆä¸Šæµ·å¸‚æ°”è±¡å±€çš„å…¶ä»–ç›¸å…³æœåŠ¡å’Œä¿¡æ¯ï¼Œå¦‚æ°”è±¡ç§‘æ™®ã€æ°”è±¡è§†é¢‘ã€æ°”å€™å˜åŒ–ç­‰ã€‚ Low 57F. Winds SSE at 5 to 10 mph. Sunny skies. High 81F. Winds SSE at 10 to 15 mph. 2% Dry conditions for the next 6 hours. Shanghai Weather Forecasts. Weather Underground provides local & long ... å¤©æ°”ç½‘æä¾›ä¸Šæµ·å¤©æ°”é¢„æŠ¥15å¤©,30å¤©,ä»Šæ—¥å¤©æ°”,æ˜Žå¤©å¤©æ°”,ä¸Šæµ·æœªæ¥ä¸€å‘¨çš„å¤©æ°”é¢„æŠ¥,ä¸Šæµ·å¤©æ°”,ä¸Šæµ·å®žæ—¶å¤©æ°”æŸ¥è¯¢,ä¸Šæµ·å¤©æ°”é¢„æŠ¥ä¸€å‘¨,7å¤©,10å¤©,40å¤©çš„å¤©æ°”æƒ…å†µã€‚æ—…æ¸¸å‡ºè¡Œ,ä»Žå¤©æ°”ç½‘å¼€å§‹! ä¸Šæµ·å¤©æ°”ç½‘æä¾›ä¸Šæµ·å¤©æ°”é¢„æŠ¥15å¤©ï¼Œä¸Šæµ·å¤©æ°”é¢„æŠ¥15å¤©æŸ¥è¯¢ï¼Œä¸Šæµ·æœªæ¥15å¤©å¤©æ°”é¢„æŠ¥ï¼Œé€šè¿‡ä¸Šæµ·å¤©æ°”é¢„æŠ¥15å¤©æŸ¥è¯¢ï¼ŒåŠæ—¶äº†è§£ä¸Šæµ·å„åœ°åŒºæœªæ¥15å¤©çš„å¤©æ°”çŠ¶å†µï¼Œæ¸©åº¦ï¼Œé™æ°´é‡ï¼Œé£Žå‘ç­‰ã€‚åŠ©æ‚¨æ”¾å¿ƒå‡ºè¡Œæ—…æ¸¸ã€‚ å¤©æ°”ç½‘æä¾›æµ¦ä¸œå¤©æ°”é¢„æŠ¥15å¤©,30å¤©,ä»Šæ—¥å¤©æ°”,æ˜Žå¤©å¤©æ°”,æµ¦ä¸œæœªæ¥ä¸€å‘¨çš„å¤©æ°”é¢„æŠ¥,ä¸Šæµ·æµ¦ä¸œæ–°åŒºå¤©æ°”,æµ¦ä¸œå®žæ—¶å¤©æ°”æŸ¥è¯¢,æµ¦ä¸œå¤©æ°”é¢„æŠ¥ä¸€å‘¨,7å¤©,10å¤©,40å¤©çš„å¤©æ°”æƒ…å†µã€‚æ—…æ¸¸å‡ºè¡Œ,ä»Žå¤©æ°”ç½‘å¼€å§‹!é€šè¿‡æœç´¢ä¸Šæµ·å¤©æ°”ï¼Œæˆ‘å¯ä»¥äº†è§£åˆ°ä»Šå¤©çš„å¤©æ°”æƒ…å†µã€‚
# Action: duckduckgo_search
# Action Input: åŒ—äº¬å¤©æ°”Winds NW at 10 to 15 mph. 0% Precip. Clear. Low near 55F. Winds light and variable. 0% Dry conditions for the next 6 hours. Beijing Weather Forecasts. Weather Underground provides local & long ... åŒ—äº¬å¤©æ°”é¢„æŠ¥. åŒ—äº¬5æœˆ15æ—¥ 05:07å¤©æ°”é¢„æŠ¥ï¼Œä»Šå¤©14â„ƒ-27â„ƒï¼Œå¤šäº‘, é£Žå‘æƒ…å†µï¼šåŒ—é£Žï¼Œæ€»é™æ°´é‡ï¼š0.00mmï¼Œç›¸å¯¹æ¹¿åº¦ï¼š26%ã€‚. åŒ—äº¬ä»Šæ—¥ç”Ÿæ´»æŒ‡æ•°: äº¤é€šæŒ‡æ•°ï¼Œè‰¯å¥½ ï¼ˆå¤©æ°”è¾ƒå¥½ï¼Œè·¯é¢å¹²ç‡¥ï¼Œäº¤é€šæ°”è±¡æ¡ä»¶è‰¯å¥½ï¼Œè½¦è¾†å¯ä»¥æ­£å¸¸è¡Œé©¶ã€‚. ï¼‰ï¼Œæ—…æ¸¸æŒ‡æ•°ï¼Œé€‚å®œ ï¼ˆå¤©æ°”è¾ƒå¥½ï¼Œé£Žç¨ ... å¤©æ°”ç½‘æä¾›åŒ—äº¬å¤©æ°”é¢„æŠ¥15å¤©,30å¤©,ä»Šæ—¥å¤©æ°”,æ˜Žå¤©å¤©æ°”,åŒ—äº¬æœªæ¥ä¸€å‘¨çš„å¤©æ°”é¢„æŠ¥,åŒ—äº¬å¤©æ°”,åŒ—äº¬å®žæ—¶å¤©æ°”æŸ¥è¯¢,åŒ—äº¬å¤©æ°”é¢„æŠ¥ä¸€å‘¨,7å¤©,10å¤©,40å¤©çš„å¤©æ°”æƒ…å†µã€‚æ—…æ¸¸å‡ºè¡Œ,ä»Žå¤©æ°”ç½‘å¼€å§‹! åŒ—äº¬ (Beijing) â˜€ 10å¤©çš„æ°”è±¡é¢„æŠ¥ï¼Œä¿¡æ¯æ¥è‡ªæ°”è±¡è§‚æµ‹ç«™ï¼Œç½‘ç»œæ‘„åƒå¤´ï¼Œæ—¥å‡ºæ—¥è½ï¼Œå½“åœ°é£Žå’Œé™æ°´å›¾ Ventusky: å¤©æ°”é¢„æŠ¥åœ°å›¾ å…³äºŽ åŒ—äº¬5æœˆ2æ—¥ 22:16å¤©æ°”é¢„æŠ¥ï¼Œä»Šå¤©11â„ƒ-28â„ƒï¼Œæ™´, é£Žå‘æƒ…å†µï¼šè¥¿å—é£Žï¼Œæ€»é™æ°´é‡ï¼š0.00mmï¼Œç›¸å¯¹æ¹¿åº¦ï¼š42%ã€‚åŒ—äº¬ä»Šæ—¥ç”Ÿæ´»æŒ‡æ•°: äº¤é€šæŒ‡æ•°ï¼Œè‰¯å¥½ ï¼ˆå¤©æ°”è¾ƒå¥½ï¼Œè·¯é¢å¹²ç‡¥ï¼Œäº¤é€šæ°”è±¡æ¡ä»¶è‰¯å¥½ï¼Œè½¦è¾†å¯ä»¥æ­£å¸¸è¡Œé©¶ã€‚ï¼‰ï¼Œæ—…æ¸¸æŒ‡æ•°ï¼Œé€‚å®œ ï¼ˆå¤©æ°”è¾ƒå¥½ï¼Œæ¸©åº¦é€‚å®œï¼Œæ˜¯ä¸ªå¥½å¤©æ°”å“¦ã€‚é€šè¿‡æœç´¢åŒ—äº¬å¤©æ°”ï¼Œæˆ‘å¯ä»¥äº†è§£åˆ°ä»Šå¤©çš„å¤©æ°”æƒ…å†µã€‚
# Thought: çŽ°åœ¨æˆ‘çŸ¥é“äº†ä¸Šæµ·å’ŒåŒ—äº¬çš„å¤©æ°”æƒ…å†µã€‚
# Final Answer: ä¸Šæµ·å’ŒåŒ—äº¬çš„æ°”æ¸©å·®æ˜¯27-14=13åº¦ã€‚

# > Finished chain.
# {'input': 'ä»Šå¤©ä¸Šæµ·å’ŒåŒ—äº¬çš„æ°”æ¸©å·®å‡ åº¦ï¼Ÿ(ç”¨ä¸­æ–‡å›žç­”)', 'output': 'ä¸Šæµ·å’ŒåŒ—äº¬çš„æ°”æ¸©å·®æ˜¯27-14=13åº¦ã€‚'}
```

