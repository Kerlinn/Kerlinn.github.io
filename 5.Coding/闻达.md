#

# 闻达：一个大规模语言模型调用平台

本项目设计目标为实现针对特定环境的高效内容生成，同时考虑个人和中小企业的计算资源局限性，以及知识安全和私密性问题。为达目标，平台化集成了以下能力：

1. 知识库：支持对接[本地离线向量库](https://github.com/wenda-LLM/wenda#rtst模式)、[本地搜索引擎](https://github.com/wenda-LLM/wenda#fess模式)、在线搜索引擎等。
2. 多种大语言模型：目前支持离线部署模型有`chatGLM-6B\chatGLM2-6B`、`chatRWKV`、`llama系列(不推荐中文用户)`、`moss(不推荐)`、`baichuan(需配合lora使用，否则效果差)`、`Aquila-7B`、`InternLM`，在线API访问`openai api`和`chatGLM-130b api`。
3. Auto脚本：通过开发插件形式的JavaScript脚本，为平台附件功能，实现包括但不限于自定义对话流程、访问外部API、在线切换LoRA模型。
4. 其他实用化所需能力：对话历史管理、内网部署、多用户同时使用等。