## 碎片化时代该如何学习？

![image-20240302215846509](./大模型研究进展（聚焦RAG）.assets/image-20240302215846509.png)

![image-20240302215900511](./大模型研究进展（聚焦RAG）.assets/image-20240302215900511.png)

### 研究搜索

- 做搜索就是一个搜索答案，找解决方案的过程，是一个解决实际问题的过程；
- 如果来一个问题你想要解决，那么首先得把问题想清楚，你就会有思考
- 有了思考你又不能把全部的思考过程放到搜索里面，这样你就会把问题浓缩成一个/若干个关键词
- 然后就会变成关键词的概括，这样变相的会去培养你总结的能力
- 搜索之后，会有很多结果，有些并不是你想要的，这时候你需要举一反三，去想其他的一些搜索词 

![image-20240302220744147](./大模型研究进展（聚焦RAG）.assets/image-20240302220744147.png)

![image-20240302220755077](./大模型研究进展（聚焦RAG）.assets/image-20240302220755077.png)

![image-20240302221049127](./大模型研究进展（聚焦RAG）.assets/image-20240302221049127.png)

![image-20240302221200004](./大模型研究进展（聚焦RAG）.assets/image-20240302221200004.png)

![image-20240302221351590](./大模型研究进展（聚焦RAG）.assets/image-20240302221351590.png)

![image-20240302221402200](./大模型研究进展（聚焦RAG）.assets/image-20240302221402200.png)

![image-20240302221435133](./大模型研究进展（聚焦RAG）.assets/image-20240302221435133.png)

![image-20240302221634364](./大模型研究进展（聚焦RAG）.assets/image-20240302221634364.png)

![image-20240302222233686](./大模型研究进展（聚焦RAG）.assets/image-20240302222233686.png)

![image-20240302222326559](./大模型研究进展（聚焦RAG）.assets/image-20240302222326559.png)

## 2024年初

![image-20240104152204105](./大模型研究进展（聚焦RAG）.assets/image-20240104152204105.png)

![image-20240104152549460](./大模型研究进展（聚焦RAG）.assets/image-20240104152549460.png)

![image-20240104152601843](./大模型研究进展（聚焦RAG）.assets/image-20240104152601843.png)





> [也谈长文本取代RAG的局限观点：兼看20240224大模型进展早报及Self-DC RAG问答框架](https://mp.weixin.qq.com/s/I-pu2bK8Ajw-e9qeLx2hbw)
>
> **RAG个大系统，就像当时KG一样，都说要替代掉，但其本身是个大系统，依旧是要往前走的，要有工程观和落地观念。**
>
> 本文主要介绍了20240224大模型进展早报以及继续关注RAG的一个工作，也重新温习了使用大模型对自身生成内容置信度估计的方案，与之前介绍内容不同的是，除了使用verblized based方案之外，还可以利用token的预测概率，如均值等，这些都是很好玩的思路。
>
> 此外，self-DC这这套方案，前置要求大模型的置信准确性，也融合了问题扩展等思路，但也存在一些问题，例如，简单问题和难问题之间存在着很大的差距，**如该工作所说的，** 对大模型的依赖性太强，当使用verblized based方法时，在**gpt-3.5-turbo-instruct**上，发现超过65%的情况下置信度得分为0，大约20%的情况下置信度得分超过0.9。但当使用**gpt-3.5-turbo-instruct**，趋势相反，给出0.9更高的频率(≈45%)，也就是说，大模型似乎要么高估了正确性，要么直接承认不确定性并拒绝回答。此外，细粒度置信分数(即0.82,0.61)相当罕见，使得β的细粒度选择毫无意义。
>
> 另一方面，当使用probb方法时，有更多的细粒度置信信号，并且大多数落在<0.5部分(≈90%)。结果表明，gpt-3.5-turbo-1106在不确定性估计方面优于gpt-3.5-turbo-instruct，prob方法优于动词方法，获得了更准确的置信度分数，分解次数受置信度分数的影响很大，这可能又会落入到一个阈值的调节怪圈里。
>
> **所以说，在NLP领域，并不存在一个放之四海而皆准的防范，都是需要特事特办，都是一堆补丁，即便有了长文本，也有一堆RAG的补丁要做。**

## 2024.1月底

> Al搜索、RAG、moe、Agent、长文本等2024年1月大模型总结——碎片化时代如何高效学习?

![image-20240301140300752](./大模型研究进展（聚焦RAG）.assets/image-20240301140300752.png)

现在很多RAG会发现太冗余了，成本高、速度慢；有一些工作尝试对检索器和生成器进行微调

![image.png](./大模型研究进展（聚焦RAG）.assets/1707808776335-d825572c-989d-45fa-bc21-bafa5642350e.png)

自然语言本身是冗余的，因此可以压缩，LLM可以有效地从压缩文本描述中重建源代码，同时保持较高的功能准确性。

![image.png](./大模型研究进展（聚焦RAG）.assets/1707809131819-180940ca-f411-4fc2-b7b8-3c6d113555cf.png)

### MOE

![image-20240302195103971](./大模型研究进展（聚焦RAG）.assets/image-20240302195103971.png)

![image-20240302195530576](./大模型研究进展（聚焦RAG）.assets/image-20240302195530576.png)

![image-20240302195559916](./大模型研究进展（聚焦RAG）.assets/image-20240302195559916.png)

![image-20240302195942813](./大模型研究进展（聚焦RAG）.assets/image-20240302195942813.png)

![image-20240302200101936](./大模型研究进展（聚焦RAG）.assets/image-20240302200101936.png)

![image-20240302200337106](./大模型研究进展（聚焦RAG）.assets/image-20240302200337106.png)

### AI搜索

> 对于对话式搜索引擎来说，**召回**+**排序**才是核心竞争力

![image-20240302202422303](./大模型研究进展（聚焦RAG）.assets/image-20240302202422303.png)

![image-20240302202538228](./大模型研究进展（聚焦RAG）.assets/image-20240302202538228.png)

#### 典型案例：Perplexity AI

![image-20240302203841938](./大模型研究进展（聚焦RAG）.assets/image-20240302203841938.png)

#### 典型案例：天工搜索

![image-20240302204259540](./大模型研究进展（聚焦RAG）.assets/image-20240302204259540.png)

#### 典型案例：360AI搜索及其他

![image-20240302204333898](./大模型研究进展（聚焦RAG）.assets/image-20240302204333898.png)

### 长文本

![image-20240302204640220](./大模型研究进展（聚焦RAG）.assets/image-20240302204640220.png)

![image-20240302204739505](./大模型研究进展（聚焦RAG）.assets/image-20240302204739505.png)

![image-20240302204922874](./大模型研究进展（聚焦RAG）.assets/image-20240302204922874.png)

![image-20240302212619784](./大模型研究进展（聚焦RAG）.assets/image-20240302212619784.png)

#### 业界代表方案

![image-20240302212754622](./大模型研究进展（聚焦RAG）.assets/image-20240302212754622.png)



#### 评测

![image-20240302212950262](./大模型研究进展（聚焦RAG）.assets/image-20240302212950262.png)

![image-20240302213019697](./大模型研究进展（聚焦RAG）.assets/image-20240302213019697.png)

#### 大海捞针

![image-20240302213056171](./大模型研究进展（聚焦RAG）.assets/image-20240302213056171.png)

### Agent

> RAG的未来就是Agent

![image-20240302213344163](./大模型研究进展（聚焦RAG）.assets/image-20240302213344163.png)

![image-20240302213554791](./大模型研究进展（聚焦RAG）.assets/image-20240302213554791.png)

![image-20240302213609646](./大模型研究进展（聚焦RAG）.assets/image-20240302213609646.png)

![image-20240302213758202](./大模型研究进展（聚焦RAG）.assets/image-20240302213758202.png)

![image-20240302214526161](./大模型研究进展（聚焦RAG）.assets/image-20240302214526161.png)

![image-20240302215329739](./大模型研究进展（聚焦RAG）.assets/image-20240302215329739.png)

![image-20240302215413956](./大模型研究进展（聚焦RAG）.assets/image-20240302215413956.png)

![image-20240302215530253](./大模型研究进展（聚焦RAG）.assets/image-20240302215530253.png)

#### 前景

![image-20240302214626956](./大模型研究进展（聚焦RAG）.assets/image-20240302214626956.png)

#### 产品

![image-20240302215100410](./大模型研究进展（聚焦RAG）.assets/image-20240302215100410.png)

![image-20240302215117805](./大模型研究进展（聚焦RAG）.assets/image-20240302215117805.png)

![image-20240302215142942](./大模型研究进展（聚焦RAG）.assets/image-20240302215142942.png)

![image-20240302215215252](./大模型研究进展（聚焦RAG）.assets/image-20240302215215252.png)

![image-20240302215233310](./大模型研究进展（聚焦RAG）.assets/image-20240302215233310.png)











## 2024.2月中旬

> OpenAI Sora、Prompt工程、RAG、表格处理、长文本、embedding变体及新晋开源的那些事儿

![image-20240224141327239](./大模型研究进展（聚焦RAG）.assets/image-20240224141327239.png)

> ChatGPT能够最多能记忆到到28轮

![image-20240224150910978](./大模型研究进展（聚焦RAG）.assets/image-20240224150910978.png)

### 布局小模型

![image-20240224151054334](./大模型研究进展（聚焦RAG）.assets/image-20240224151054334.png)

![image-20240224151214465](./大模型研究进展（聚焦RAG）.assets/image-20240224151214465.png)

### 长文本

![image-20240224151341382](./大模型研究进展（聚焦RAG）.assets/image-20240224151341382.png)

![image-20240224151502555](./大模型研究进展（聚焦RAG）.assets/image-20240224151502555.png)

### 面向RAG的embedding变体进展：压缩及灵活伸缩

![image-20240224151701933](./大模型研究进展（聚焦RAG）.assets/image-20240224151701933.png)

> 长文本这么搞是很占内存的，所以后面有人用俄罗斯套娃的方式去做

![image-20240224151827470](./大模型研究进展（聚焦RAG）.assets/image-20240224151827470.png)

#### 如何衡量大模型对答案的不确定性

![image-20240302225821174](./大模型研究进展（聚焦RAG）.assets/image-20240302225821174.png)

> 自信等级、一致性、结合
>
> 不同模型是有偏的

#### 提升鲁棒性

![image-20240302230142982](./大模型研究进展（聚焦RAG）.assets/image-20240302230142982.png)

![image-20240302230403372](./大模型研究进展（聚焦RAG）.assets/image-20240302230403372.png)

#### 聚类处理复杂长文本



#### 引入实体识别

![image-20240302231500446](./大模型研究进展（聚焦RAG）.assets/image-20240302231500446.png)

> T-RAG：你去做向量化检索的时候，能不能顺带去做一下组织里的实体，然后再把实体对应的东西给召回出来。

![image-20240302231222565](./大模型研究进展（聚焦RAG）.assets/image-20240302231222565.png)

![image-20240302231744652](./大模型研究进展（聚焦RAG）.assets/image-20240302231744652.png)

### 文档智能中的表格处理方案：表示与建模
