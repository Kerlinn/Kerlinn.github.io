## 碎片化时代该如何学习？

![image-20240302215846509](./大模型研究进展（聚焦RAG）.assets/image-20240302215846509.png)

![image-20240302215900511](./大模型研究进展（聚焦RAG）.assets/image-20240302215900511.png)

### 研究搜索

- 做搜索就是一个搜索答案，找解决方案的过程，是一个解决实际问题的过程；
- 如果来一个问题你想要解决，那么首先得把问题想清楚，你就会有思考
- 有了思考你又不能把全部的思考过程放到搜索里面，这样你就会把问题浓缩成一个/若干个关键词
- 然后就会变成关键词的概括，这样变相的会去培养你总结的能力
- 搜索之后，会有很多结果，有些并不是你想要的，这时候你需要举一反三，去想其他的一些搜索词 

![image-20240302220744147](./大模型研究进展（聚焦RAG）.assets/image-20240302220744147.png)

![image-20240302220755077](./大模型研究进展（聚焦RAG）.assets/image-20240302220755077.png)

![image-20240302221049127](./大模型研究进展（聚焦RAG）.assets/image-20240302221049127.png)

![image-20240302221200004](./大模型研究进展（聚焦RAG）.assets/image-20240302221200004.png)

![image-20240302221351590](./大模型研究进展（聚焦RAG）.assets/image-20240302221351590.png)

![image-20240302221402200](./大模型研究进展（聚焦RAG）.assets/image-20240302221402200.png)

![image-20240302221435133](./大模型研究进展（聚焦RAG）.assets/image-20240302221435133.png)

![image-20240302221634364](./大模型研究进展（聚焦RAG）.assets/image-20240302221634364.png)

![image-20240302222233686](./大模型研究进展（聚焦RAG）.assets/image-20240302222233686.png)

![image-20240302222326559](./大模型研究进展（聚焦RAG）.assets/image-20240302222326559.png)

## 2024年初

![image-20240104152204105](./大模型研究进展（聚焦RAG）.assets/image-20240104152204105.png)

![image-20240104152549460](./大模型研究进展（聚焦RAG）.assets/image-20240104152549460.png)

![image-20240104152601843](./大模型研究进展（聚焦RAG）.assets/image-20240104152601843.png)





> [也谈长文本取代RAG的局限观点：兼看20240224大模型进展早报及Self-DC RAG问答框架](https://mp.weixin.qq.com/s/I-pu2bK8Ajw-e9qeLx2hbw)
>
> **RAG个大系统，就像当时KG一样，都说要替代掉，但其本身是个大系统，依旧是要往前走的，要有工程观和落地观念。**
>
> 本文主要介绍了20240224大模型进展早报以及继续关注RAG的一个工作，也重新温习了使用大模型对自身生成内容置信度估计的方案，与之前介绍内容不同的是，除了使用verblized based方案之外，还可以利用token的预测概率，如均值等，这些都是很好玩的思路。
>
> 此外，self-DC这这套方案，前置要求大模型的置信准确性，也融合了问题扩展等思路，但也存在一些问题，例如，简单问题和难问题之间存在着很大的差距，**如该工作所说的，** 对大模型的依赖性太强，当使用verblized based方法时，在**gpt-3.5-turbo-instruct**上，发现超过65%的情况下置信度得分为0，大约20%的情况下置信度得分超过0.9。但当使用**gpt-3.5-turbo-instruct**，趋势相反，给出0.9更高的频率(≈45%)，也就是说，大模型似乎要么高估了正确性，要么直接承认不确定性并拒绝回答。此外，细粒度置信分数(即0.82,0.61)相当罕见，使得β的细粒度选择毫无意义。
>
> 另一方面，当使用probb方法时，有更多的细粒度置信信号，并且大多数落在<0.5部分(≈90%)。结果表明，gpt-3.5-turbo-1106在不确定性估计方面优于gpt-3.5-turbo-instruct，prob方法优于动词方法，获得了更准确的置信度分数，分解次数受置信度分数的影响很大，这可能又会落入到一个阈值的调节怪圈里。
>
> **所以说，在NLP领域，并不存在一个放之四海而皆准的防范，都是需要特事特办，都是一堆补丁，即便有了长文本，也有一堆RAG的补丁要做。**

## 2024.1月底

> Al搜索、RAG、moe、Agent、长文本等2024年1月大模型总结——碎片化时代如何高效学习?

![image-20240301140300752](./大模型研究进展（聚焦RAG）.assets/image-20240301140300752.png)

现在很多RAG会发现太冗余了，成本高、速度慢；有一些工作尝试对检索器和生成器进行微调

![image.png](./大模型研究进展（聚焦RAG）.assets/1707808776335-d825572c-989d-45fa-bc21-bafa5642350e.png)

自然语言本身是冗余的，因此可以压缩，LLM可以有效地从压缩文本描述中重建源代码，同时保持较高的功能准确性。

![image.png](./大模型研究进展（聚焦RAG）.assets/1707809131819-180940ca-f411-4fc2-b7b8-3c6d113555cf.png)

### MOE

![image-20240302195103971](./大模型研究进展（聚焦RAG）.assets/image-20240302195103971.png)

![image-20240302195530576](./大模型研究进展（聚焦RAG）.assets/image-20240302195530576.png)

![image-20240302195559916](./大模型研究进展（聚焦RAG）.assets/image-20240302195559916.png)

![image-20240302195942813](./大模型研究进展（聚焦RAG）.assets/image-20240302195942813.png)

![image-20240302200101936](./大模型研究进展（聚焦RAG）.assets/image-20240302200101936.png)

![image-20240302200337106](./大模型研究进展（聚焦RAG）.assets/image-20240302200337106.png)

### AI搜索

> 对于对话式搜索引擎来说，**召回**+**排序**才是核心竞争力

![image-20240302202422303](./大模型研究进展（聚焦RAG）.assets/image-20240302202422303.png)

![image-20240302202538228](./大模型研究进展（聚焦RAG）.assets/image-20240302202538228.png)

#### 典型案例：Perplexity AI

![image-20240302203841938](./大模型研究进展（聚焦RAG）.assets/image-20240302203841938.png)

#### 典型案例：天工搜索

![image-20240302204259540](./大模型研究进展（聚焦RAG）.assets/image-20240302204259540.png)

#### 典型案例：360AI搜索及其他

![image-20240302204333898](./大模型研究进展（聚焦RAG）.assets/image-20240302204333898.png)

### 长文本

![image-20240302204640220](./大模型研究进展（聚焦RAG）.assets/image-20240302204640220.png)

![image-20240302204739505](./大模型研究进展（聚焦RAG）.assets/image-20240302204739505.png)

![image-20240302204922874](./大模型研究进展（聚焦RAG）.assets/image-20240302204922874.png)

![image-20240302212619784](./大模型研究进展（聚焦RAG）.assets/image-20240302212619784.png)

#### 业界代表方案

![image-20240302212754622](./大模型研究进展（聚焦RAG）.assets/image-20240302212754622.png)



#### 评测

![image-20240302212950262](./大模型研究进展（聚焦RAG）.assets/image-20240302212950262.png)

![image-20240302213019697](./大模型研究进展（聚焦RAG）.assets/image-20240302213019697.png)

#### 大海捞针

![image-20240302213056171](./大模型研究进展（聚焦RAG）.assets/image-20240302213056171.png)

### Agent

> RAG的未来就是Agent
>
> - Base模型（有指令微调）要10B以上；
> - 专门要做指令增强的强化
> - 要有意图识别
> - langchain-chatchat-v3
> - AutoGen、AutoGen Studio-v2有完备的可视化界面，多智能体定制很容易，效果很好
> - 目前还是用英文来训练，中文还不行
> - 训完之后去找适合自己任务的足够新的框架
> - 清晰数据还是尽量用成体系的Prompt Engineer来做，人来做的话，模型能力反而可能降低
> - ![image-20240321184722968](./大模型研究进展（聚焦RAG）.assets/image-20240321184722968.png)

![image-20240302213344163](./大模型研究进展（聚焦RAG）.assets/image-20240302213344163.png)

![image-20240302213554791](./大模型研究进展（聚焦RAG）.assets/image-20240302213554791.png)

![image-20240302213609646](./大模型研究进展（聚焦RAG）.assets/image-20240302213609646.png)

![image-20240302213758202](./大模型研究进展（聚焦RAG）.assets/image-20240302213758202.png)

![image-20240302214526161](./大模型研究进展（聚焦RAG）.assets/image-20240302214526161.png)

![image-20240302215329739](./大模型研究进展（聚焦RAG）.assets/image-20240302215329739.png)

![image-20240302215413956](./大模型研究进展（聚焦RAG）.assets/image-20240302215413956.png)

![image-20240302215530253](./大模型研究进展（聚焦RAG）.assets/image-20240302215530253.png)

#### 前景

![image-20240302214626956](./大模型研究进展（聚焦RAG）.assets/image-20240302214626956.png)

#### 产品

![image-20240302215100410](./大模型研究进展（聚焦RAG）.assets/image-20240302215100410.png)

![image-20240302215117805](./大模型研究进展（聚焦RAG）.assets/image-20240302215117805.png)

![image-20240302215142942](./大模型研究进展（聚焦RAG）.assets/image-20240302215142942.png)

![image-20240302215215252](./大模型研究进展（聚焦RAG）.assets/image-20240302215215252.png)

![image-20240302215233310](./大模型研究进展（聚焦RAG）.assets/image-20240302215233310.png)











## 2024.2月中旬

> OpenAI Sora、Prompt工程、RAG、表格处理、长文本、embedding变体及新晋开源的那些事儿

![image-20240224141327239](./大模型研究进展（聚焦RAG）.assets/image-20240224141327239.png)

> ChatGPT能够最多能记忆到到28轮

![image-20240224150910978](./大模型研究进展（聚焦RAG）.assets/image-20240224150910978.png)

### 布局小模型

![image-20240224151054334](./大模型研究进展（聚焦RAG）.assets/image-20240224151054334.png)

![image-20240224151214465](./大模型研究进展（聚焦RAG）.assets/image-20240224151214465.png)

### 长文本

![image-20240224151341382](./大模型研究进展（聚焦RAG）.assets/image-20240224151341382.png)

![image-20240224151502555](./大模型研究进展（聚焦RAG）.assets/image-20240224151502555.png)

### 面向RAG的embedding变体进展：压缩及灵活伸缩

![image-20240224151701933](./大模型研究进展（聚焦RAG）.assets/image-20240224151701933.png)

> 长文本这么搞是很占内存的，所以后面有人用俄罗斯套娃的方式去做

![image-20240224151827470](./大模型研究进展（聚焦RAG）.assets/image-20240224151827470.png)

#### 如何衡量大模型对答案的不确定性

![image-20240302225821174](./大模型研究进展（聚焦RAG）.assets/image-20240302225821174.png)

> 自信等级、一致性、结合
>
> 不同模型是有偏的

#### 提升鲁棒性

![image-20240302230142982](./大模型研究进展（聚焦RAG）.assets/image-20240302230142982.png)

![image-20240302230403372](./大模型研究进展（聚焦RAG）.assets/image-20240302230403372.png)

#### 聚类处理复杂长文本



#### 引入实体识别

![image-20240302231500446](./大模型研究进展（聚焦RAG）.assets/image-20240302231500446.png)

> T-RAG：你去做向量化检索的时候，能不能顺带去做一下组织里的实体，然后再把实体对应的东西给召回出来。

![image-20240302231222565](./大模型研究进展（聚焦RAG）.assets/image-20240302231222565.png)

![image-20240302231744652](./大模型研究进展（聚焦RAG）.assets/image-20240302231744652.png)

### 文档智能中的表格处理方案：表示与建模

> 开源项目：ChatDB、ChatExcel

![image-20240304191630111](./大模型研究进展（聚焦RAG）.assets/image-20240304191630111.png)

![image-20240304191802392](./大模型研究进展（聚焦RAG）.assets/image-20240304191802392.png)

> 简单表格用markdown，复杂表格用Latex或者HTML

![image-20240304192313703](./大模型研究进展（聚焦RAG）.assets/image-20240304192313703.png)

![image-20240304192006846](./大模型研究进展（聚焦RAG）.assets/image-20240304192006846.png)

![image-20240304192145811](./大模型研究进展（聚焦RAG）.assets/image-20240304192145811.png)

### 大模型性能提升中的prompt工程策略

![image-20240304193356487](./大模型研究进展（聚焦RAG）.assets/image-20240304193356487.png)

> 推荐 ↑ 这篇综述

#### ==Logical CoT==

![image-20240304194756008](./大模型研究进展（聚焦RAG）.assets/image-20240304194756008.png)

![image-20240304194933858](./大模型研究进展（聚焦RAG）.assets/image-20240304194933858.png)

![image-20240304195056588](./大模型研究进展（聚焦RAG）.assets/image-20240304195056588.png)

![image-20240304195118511](./大模型研究进展（聚焦RAG）.assets/image-20240304195118511.png)

![image-20240304195238942](./大模型研究进展（聚焦RAG）.assets/image-20240304195238942.png)

> ↑ 有点像RAG的query rewrite

![image-20240304203509578](./大模型研究进展（聚焦RAG）.assets/image-20240304203509578.png)

> ↑ 类似于 RAG-fusion：一个问题，一次性解决不了的时候就分而治之

![image-20240304203752158](./大模型研究进展（聚焦RAG）.assets/image-20240304203752158.png)

![image-20240304203851189](./大模型研究进展（聚焦RAG）.assets/image-20240304203851189.png)

### 人工智能在视频生成领域的应用：Sora

![image-20240304204003621](./大模型研究进展（聚焦RAG）.assets/image-20240304204003621.png)

![image-20240304204158871](./大模型研究进展（聚焦RAG）.assets/image-20240304204158871.png)

![image-20240304204543824](./大模型研究进展（聚焦RAG）.assets/image-20240304204543824.png)

![image-20240304204649297](./大模型研究进展（聚焦RAG）.assets/image-20240304204649297.png)

![image-20240304204728769](./大模型研究进展（聚焦RAG）.assets/image-20240304204728769.png)

![image-20240304204855970](./大模型研究进展（聚焦RAG）.assets/image-20240304204855970.png)

![image-20240304212818632](./大模型研究进展（聚焦RAG）.assets/image-20240304212818632.png)

![image-20240304213338262](./大模型研究进展（聚焦RAG）.assets/image-20240304213338262.png)

### 其他

![image-20240304213529755](./大模型研究进展（聚焦RAG）.assets/image-20240304213529755.png)

![image-20240304213601631](./大模型研究进展（聚焦RAG）.assets/image-20240304213601631.png)

#### AI搜索

![image-20240304213628008](./大模型研究进展（聚焦RAG）.assets/image-20240304213628008.png)

![image-20240304213708696](./大模型研究进展（聚焦RAG）.assets/image-20240304213708696.png)

### 总结

![image-20240304213800789](./大模型研究进展（聚焦RAG）.assets/image-20240304213800789.png)

## 2024.3月初

> OpenAl Sora、RAG、KG-RAG、长文本及前沿工作、开源项目进展

### 2月份下半月大模型产研关键事件进展盘点: sora逆向工程

![image-20240321110011421](./大模型研究进展（聚焦RAG）.assets/image-20240321110011421.png)

![image-20240321110042568](./大模型研究进展（聚焦RAG）.assets/image-20240321110042568.png)

### 值得关注的大模型开源项目及前沿工作:爆发性的大模型全方面总结工作

#### 大模型训练资源

![image-20240321110118692](./大模型研究进展（聚焦RAG）.assets/image-20240321110118692.png)

#### 多轮对话评估

![image-20240321110508785](./大模型研究进展（聚焦RAG）.assets/image-20240321110508785.png)

#### 信息抽取

![image-20240321110733127](./大模型研究进展（聚焦RAG）.assets/image-20240321110733127.png)

![image-20240321110753772](./大模型研究进展（聚焦RAG）.assets/image-20240321110753772.png)

#### 数据标注

![image-20240321110858280](./大模型研究进展（聚焦RAG）.assets/image-20240321110858280.png)

#### 知识蒸馏

![image-20240321110931234](./大模型研究进展（聚焦RAG）.assets/image-20240321110931234.png)

#### 智能体Agent

![image-20240321111115137](./大模型研究进展（聚焦RAG）.assets/image-20240321111115137.png)

#### 多轮对话

![image-20240321111234350](./大模型研究进展（聚焦RAG）.assets/image-20240321111234350.png)

![image-20240321112025945](./大模型研究进展（聚焦RAG）.assets/image-20240321112025945.png)

#### 继续预训练与微调

![image-20240321111253165](./大模型研究进展（聚焦RAG）.assets/image-20240321111253165.png)

#### 文档智能：未来的图生文可能不仅仅是信息抽取、还有公式识别等等

![image-20240321111447556](./大模型研究进展（聚焦RAG）.assets/image-20240321111447556.png)

#### PDF处理包：fitz

![image-20240321111902832](./大模型研究进展（聚焦RAG）.assets/image-20240321111902832.png)

#### Prompt工程优化

![image-20240321112025945](./大模型研究进展（聚焦RAG）.assets/image-20240321112025945.png)



### 多模态视觉语言模型进展:一些开源的图文生成项目

#### VisualGLM-6B

![image-20240321112829655](./大模型研究进展（聚焦RAG）.assets/image-20240321112829655.png)

> 本质上是VQA，对给出的图片进行问答

![image-20240321113027214](./大模型研究进展（聚焦RAG）.assets/image-20240321113027214.png)

#### MiniGPT-4

![image-20240321113215777](./大模型研究进展（聚焦RAG）.assets/image-20240321113215777.png)

#### BLIP-2

![image-20240321121047162](./大模型研究进展（聚焦RAG）.assets/image-20240321121047162.png)

![image-20240321121027921](./大模型研究进展（聚焦RAG）.assets/image-20240321121027921.png)

#### Qwen-VL

![image-20240321121457733](./大模型研究进展（聚焦RAG）.assets/image-20240321121457733.png)

> Qwen-VL已经冲到了榜单前列
>
> https://github.com/QwenLM/Qwen-VL/blob/master/README_CN.md
>
> ![image-20240321121726934](./大模型研究进展（聚焦RAG）.assets/image-20240321121726934.png)













### RAG最新进展:多模态、长文本替代?、鲁棒性

> **为什么要讲多模态，因为未来的RAG一定要往长文本、多模态等方向发展。**

#### 多模态RAG

![image-20240321122137801](./大模型研究进展（聚焦RAG）.assets/image-20240321122137801.png)

- 方法1：使用V2L模型将视频/图片翻译成文本，然后构造Prompt

![image-20240321122227044](./大模型研究进展（聚焦RAG）.assets/image-20240321122227044.png)

- 将各种数据使用【同一个Embedding模型】嵌入到一个文本空间中，分四路召回，分别送入对应模型。

![image-20240321122310943](./大模型研究进展（聚焦RAG）.assets/image-20240321122310943.png)



![image-20240321122759619](./大模型研究进展（聚焦RAG）.assets/image-20240321122759619.png)



![image-20240321123051500](./大模型研究进展（聚焦RAG）.assets/image-20240321123051500.png)

> 如何量化不确定性？可以用其他的模型来评判

#### 长文本无法取代RAG

> https://www.rungalileo.io/blog/mastering-rag-how-to-architect-an-enterprise-rag-system

![rag_architecture](./大模型研究进展（聚焦RAG）.assets/rag_architecture.gif)

![image-20240321123942484](./大模型研究进展（聚焦RAG）.assets/image-20240321123942484.png)

**RAG是一个很庞大的系统，和单纯的长文本完全是两个东西，长文本模型只是RAG中众多pipeline中（问题改写、切分、排序、噪声控制、重排、融合sq|\kg, 答案生成、答案组合等其他模块）答案生成这个小模块，当然也可以用到rank-embedding等，长文本的输入长了，可以降低切分、rank这类模块的必要性，但绝对不会是所谓的取代观点，比如我要调用kg，转text2sq|等， 怎么做才能应对不同的检索问答需求，这是工程上需要考虑的点。**

![image-20240321124704907](./大模型研究进展（聚焦RAG）.assets/image-20240321124704907.png)

#### 如何提升RAG的鲁棒性

![image-20240321124841566](./大模型研究进展（聚焦RAG）.assets/image-20240321124841566.png)





### KG+RAG的实现范式及开源实践

![image-20240321125545638](./大模型研究进展（聚焦RAG）.assets/image-20240321125545638.png)

![image-20240321125700948](./大模型研究进展（聚焦RAG）.assets/image-20240321125700948.png)

![image-20240321125738031](./大模型研究进展（聚焦RAG）.assets/image-20240321125738031.png)

#### KG增强LLM问答

![image-20240321131321318](./大模型研究进展（聚焦RAG）.assets/image-20240321131321318.png)

![image-20240321131356237](./大模型研究进展（聚焦RAG）.assets/image-20240321131356237.png)

![image-20240321150522807](./大模型研究进展（聚焦RAG）.assets/image-20240321150522807.png)

![image-20240321150609402](./大模型研究进展（聚焦RAG）.assets/image-20240321150609402.png)

![image-20240321150739750](./大模型研究进展（聚焦RAG）.assets/image-20240321150739750.png)

![image-20240321150832777](./大模型研究进展（聚焦RAG）.assets/image-20240321150832777.png)

![image-20240321150913540](./大模型研究进展（聚焦RAG）.assets/image-20240321150913540.png)

### 总结

![image-20240321152504257](./大模型研究进展（聚焦RAG）.assets/image-20240321152504257.png)

## 2024.3月中旬

> Claude_3、Devin、大模型AI搜索、长文本、RAG、LLM+KG知识推理、碎片化时代如何高效搜索

### 3月份上半月大模型进展总结

#### Claude_3、 Devin等关键事件

![image-20240321153147438](./大模型研究进展（聚焦RAG）.assets/image-20240321153147438.png)

![image-20240321153353928](./大模型研究进展（聚焦RAG）.assets/image-20240321153353928.png)

> 底层可以理解为AutoGPT

#### 大模型Al搜索、文档Al软件进展

> 以**摘要**为核心的搜索：
>
> 1. query意图理解：query的分析（去停用词、实体识别、关键词提取、归一化等）；
> 2. query扩展：一个query扩展成多个sub query, 以扩大召回面，形成标准和多样化的query集合；
> 3. 并发检索：针对query进行并发检索；
> 4. 检索后再进行粗排、精排：召回出符合特定阈值的相关网页文档；
> 5. 追加至prompt：让大模型进行总结回答，给出对应的链接。
>
> - 在query泛化上不受控制，可以借助预先建设好的知识图谱进行控制。

![image-20240321153613189](./大模型研究进展（聚焦RAG）.assets/image-20240321153613189.png)

![image-20240321154551540](./大模型研究进展（聚焦RAG）.assets/image-20240321154551540.png)

> 比如今天想去滑雪：先给出一系列的目录，比如滑雪的技巧，地点，天气，装备等等，这样相当于把用户query给扩充了，再单独生成对应的内容，这样更精确。

> **用大模型做AI搜索更多地是充当一个润色的作用，会出现幻觉和query漂移，如何跟图谱结合，这方面可以去做跟进。**

![image-20240321163350419](./大模型研究进展（聚焦RAG）.assets/image-20240321163350419.png)

![image-20240321163445694](./大模型研究进展（聚焦RAG）.assets/image-20240321163445694.png)

![image-20240321164542003](./大模型研究进展（聚焦RAG）.assets/image-20240321164542003.png)

> 做微调也可以直接拿这个东西去试

> **任务评估数据集，一方面给大家做评估展示、另一方面也可以拿着公开的数据集去做训练**

#### RAG、KG+LLM相关进展

##### RAG多轮问答

![image-20240321164924445](./大模型研究进展（聚焦RAG）.assets/image-20240321164924445.png)

##### Transformer Debugger，模型可解释工具

![image-20240321165053944](./大模型研究进展（聚焦RAG）.assets/image-20240321165053944.png)

![image-20240321165422460](./大模型研究进展（聚焦RAG）.assets/image-20240321165422460.png)

> 传统的检索技术可能不是最优的，需要针对【【语言生成模型与检索整合】的特定需求】开发专门的方法

![image-20240321165642263](./大模型研究进展（聚焦RAG）.assets/image-20240321165642263.png)

> Donut：目录信息辅助文档处理







#### 大模型训练、长文本进展









### 碎片化时代如何高效搜索

#### 数据报告

![image-20240321170137760](./大模型研究进展（聚焦RAG）.assets/image-20240321170137760.png)

![image-20240321170205642](./大模型研究进展（聚焦RAG）.assets/image-20240321170205642.png)

![image-20240321170219012](./大模型研究进展（聚焦RAG）.assets/image-20240321170219012.png)

#### 数据集

![image-20240321170233768](./大模型研究进展（聚焦RAG）.assets/image-20240321170233768.png)

![image-20240321170246724](./大模型研究进展（聚焦RAG）.assets/image-20240321170246724.png)

![image-20240321170302619](./大模型研究进展（聚焦RAG）.assets/image-20240321170302619.png)

![image-20240321170327456](./大模型研究进展（聚焦RAG）.assets/image-20240321170327456.png)

![image-20240321170347608](./大模型研究进展（聚焦RAG）.assets/image-20240321170347608.png)

#### 文本处理工具

![image-20240321170409228](./大模型研究进展（聚焦RAG）.assets/image-20240321170409228.png)

![image-20240321170440256](./大模型研究进展（聚焦RAG）.assets/image-20240321170440256.png)

> 做NLP的人一定要会的，爬虫；简单的就request，工程量比较大的就scrapy

![image-20240321170558839](./大模型研究进展（聚焦RAG）.assets/image-20240321170558839.png)

> 不会写代码就用curlconverter

![image-20240321170713129](./大模型研究进展（聚焦RAG）.assets/image-20240321170713129.png)



### 最后的总结

![image-20240321171824938](./大模型研究进展（聚焦RAG）.assets/image-20240321171824938.png)

![image-20240321182139479](./大模型研究进展（聚焦RAG）.assets/image-20240321182139479.png)

![image-20240321182222793](./大模型研究进展（聚焦RAG）.assets/image-20240321182222793.png)

![image-20240321182353865](./大模型研究进展（聚焦RAG）.assets/image-20240321182353865.png)

![image-20240321182545645](./大模型研究进展（聚焦RAG）.assets/image-20240321182545645.png)

![image-20240321182823025](./大模型研究进展（聚焦RAG）.assets/image-20240321182823025.png)

