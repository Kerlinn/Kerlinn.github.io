# CCF-NLP走进高校之走进华东师范大学

## 大模型时代知识处理新范式

![image-20240507191939698](./会议&汇报&分享.assets/image-20240507191939698.png)

![image-20240507192250505](./会议&汇报&分享.assets/image-20240507192250505.png)

![image-20240507192310720](./会议&汇报&分享.assets/image-20240507192310720.png)

### 大模型知识更新（参数不变）

![image-20240507192402865](./会议&汇报&分享.assets/image-20240507192402865.png)

#### 参数插件

![image-20240507192452351](./会议&汇报&分享.assets/image-20240507192452351.png)

#### 记忆辅助

![image-20240507192519189](./会议&汇报&分享.assets/image-20240507192519189.png)

![image-20240507192543527](./会议&汇报&分享.assets/image-20240507192543527.png)

### Key Point

![image-20240507192610171](./会议&汇报&分享.assets/image-20240507192610171.png)

![image-20240507192748568](./会议&汇报&分享.assets/image-20240507192748568.png)

### 大模型对齐

![image-20240507195015717](./会议&汇报&分享.assets/image-20240507195015717.png)

![image-20240507195114506](./会议&汇报&分享.assets/image-20240507195114506.png)

![image-20240507195038495](./会议&汇报&分享.assets/image-20240507195038495.png)

![image-20240507195152818](./会议&汇报&分享.assets/image-20240507195152818.png)

![image-20240507195403586](./会议&汇报&分享.assets/image-20240507195403586.png)

## 大模型技术的研发与思考

![image-20240507200141181](./会议&汇报&分享.assets/image-20240507200141181.png)

![image-20240507200206842](./会议&汇报&分享.assets/image-20240507200206842.png)

### 语言模型能力的建立：预训练

![image-20240507200345298](./会议&汇报&分享.assets/image-20240507200345298.png)

![image-20240507200431742](./会议&汇报&分享.assets/image-20240507200431742.png)

![image-20240507200636212](./会议&汇报&分享.assets/image-20240507200636212.png)

### Scaling law

![image-20240507200808850](./会议&汇报&分享.assets/image-20240507200808850.png)

![image-20240507200851447](./会议&汇报&分享.assets/image-20240507200851447.png)

![image-20240507202324092](./会议&汇报&分享.assets/image-20240507202324092.png)

### 数据资源建设

![image-20240507202353662](./会议&汇报&分享.assets/image-20240507202353662.png)

![image-20240507202615817](./会议&汇报&分享.assets/image-20240507202615817.png)

#### 到底需要多少数据？

![image-20240507202626024](./会议&汇报&分享.assets/image-20240507202626024.png)

![image-20240507202756736](./会议&汇报&分享.assets/image-20240507202756736.png)

#### 预训练→数据工程

![image-20240507202902039](./会议&汇报&分享.assets/image-20240507202902039.png)

![image-20240507202945665](./会议&汇报&分享.assets/image-20240507202945665.png)

### 复现GPT-4仍然很难

![image-20240507203324710](./会议&汇报&分享.assets/image-20240507203324710.png)

![image-20240507203430714](./会议&汇报&分享.assets/image-20240507203430714.png)

![image-20240507203654369](./会议&汇报&分享.assets/image-20240507203654369.png)

### 语言模型能力的建立：SFT&RLHF

#### 指令微调（Supervised Fine-tuning，STF）

![image-20240507203930539](./会议&汇报&分享.assets/image-20240507203930539.png)

![image-20240507204317465](./会议&汇报&分享.assets/image-20240507204317465.png)

![image-20240507204358172](./会议&汇报&分享.assets/image-20240507204358172.png)

#### 人类反馈强化学习（Reinforcement Learning with  Human Feedback，RLHF）

![image-20240507204446230](./会议&汇报&分享.assets/image-20240507204446230.png)

![image-20240507204630704](./会议&汇报&分享.assets/image-20240507204630704.png)

#### 其他

![image-20240507204722299](./会议&汇报&分享.assets/image-20240507204722299.png)

![image-20240507204840648](./会议&汇报&分享.assets/image-20240507204840648.png)

![image-20240507204902993](./会议&汇报&分享.assets/image-20240507204902993.png)

### AI研究之路

![image-20240507205400797](./会议&汇报&分享.assets/image-20240507205400797.png)

![image-20240507205409724](./会议&汇报&分享.assets/image-20240507205409724.png)

![image-20240507205618824](./会议&汇报&分享.assets/image-20240507205618824.png)

![image-20240507205643519](./会议&汇报&分享.assets/image-20240507205643519.png)

# CCF-TF131：知识图谱之检索增强技术

## RAG落地中的文档理解及知识库建设实践

### 实现路线

![image-20240508151958725](./会议&汇报&分享.assets/image-20240508151958725.png)

![image-20240508152028783](./会议&汇报&分享.assets/image-20240508152028783.png)

![image-20240508152044156](./会议&汇报&分享.assets/image-20240508152044156.png)

![image-20240508152323731](./会议&汇报&分享.assets/image-20240508152323731.png)

### 具体方案

![image-20240508152335405](./会议&汇报&分享.assets/image-20240508152335405.png)

![image-20240508152355520](./会议&汇报&分享.assets/image-20240508152355520.png)

![image-20240508152422874](./会议&汇报&分享.assets/image-20240508152422874.png)

![image-20240508152439077](./会议&汇报&分享.assets/image-20240508152439077.png)

![image-20240508152453136](./会议&汇报&分享.assets/image-20240508152453136.png)

![image-20240508152508095](./会议&汇报&分享.assets/image-20240508152508095.png)

![image-20240508152520838](./会议&汇报&分享.assets/image-20240508152520838.png)

![image-20240508152539246](./会议&汇报&分享.assets/image-20240508152539246.png)

![image-20240508152600968](./会议&汇报&分享.assets/image-20240508152600968.png)

![image-20240508152622009](./会议&汇报&分享.assets/image-20240508152622009.png)

![image-20240508152637089](./会议&汇报&分享.assets/image-20240508152637089.png)

## GTE-Embedding/Ranking统一文本表示与排序模型

![image-20240508154042116](./会议&汇报&分享.assets/image-20240508154042116.png)

### OpenAI的技术路径

![image-20240508154115530](./会议&汇报&分享.assets/image-20240508154115530.png)

### Embedding路径

![image-20240508154133254](./会议&汇报&分享.assets/image-20240508154133254.png)

### 训练一个通用的语言模型主要分为三个部分

![image-20240508155354414](./会议&汇报&分享.assets/image-20240508155354414.png)

![image-20240508155722452](./会议&汇报&分享.assets/image-20240508155722452.png)

## 有道QAnything的落地经验分享

### QAnything演化史

![image-20240508160512571](./会议&汇报&分享.assets/image-20240508160512571.png)

![image-20240508160521939](./会议&汇报&分享.assets/image-20240508160521939.png)

![image-20240508160601114](./会议&汇报&分享.assets/image-20240508160601114.png)

![image-20240508160623111](./会议&汇报&分享.assets/image-20240508160623111.png)

![image-20240508160746433](./会议&汇报&分享.assets/image-20240508160746433.png)

![image-20240508161006861](./会议&汇报&分享.assets/image-20240508161006861.png)

![image-20240508161046354](./会议&汇报&分享.assets/image-20240508161046354.png)





# 人大高瓴 - 生成式信息检索研究进展与趋势展望

## 传统与大模型时代的信息检索

### 信息检索系统：搜索引擎

![image-20240531093103093](./会议&汇报&分享.assets/image-20240531093103093.png)

#### 一个成功的商业化搜索引擎架构

![image-20240531100250147](./会议&汇报&分享.assets/image-20240531100250147.png)

### 信息检索系统：大语言模型

![image-20240531100559901](./会议&汇报&分享.assets/image-20240531100559901.png)

### 二者对比

![image-20240531100611708](./会议&汇报&分享.assets/image-20240531100611708.png)

### 大模型+检索 → 生成式信息检索

![image-20240531100706021](./会议&汇报&分享.assets/image-20240531100706021.png)

![image-20240531100846148](./会议&汇报&分享.assets/image-20240531100846148.png)

> LLM已经比最熟练的标注工的数据标注效果更好

![image-20240531101322666](./会议&汇报&分享.assets/image-20240531101322666.png)

## 大模型赋能的信息检索

![image-20240531101446395](./会议&汇报&分享.assets/image-20240531101446395.png)

> https://arxiv.org/abs/2308.07107

![image-20240531105559399](./会议&汇报&分享.assets/image-20240531105559399.png)

![image-20240531110005740](./会议&汇报&分享.assets/image-20240531110005740.png)

![image-20240531111905338](./会议&汇报&分享.assets/image-20240531111905338.png)

![image-20240531112028065](./会议&汇报&分享.assets/image-20240531112028065.png)

![image-20240531112039414](./会议&汇报&分享.assets/image-20240531112039414.png)

![image-20240531112110757](./会议&汇报&分享.assets/image-20240531112110757.png)

![image-20240531113002903](./会议&汇报&分享.assets/image-20240531113002903.png)

> **部分任务的效果：微调小模型 > 大模型**

![image-20240531113147950](./会议&汇报&分享.assets/image-20240531113147950.png)

> **任务级别的泛化性**：去掉一个任务，那剩下的数据做微调，再在去掉的结果上去评估效果

![image-20240531113756978](./会议&汇报&分享.assets/image-20240531113756978.png)

## 检索增强的大模型

![image-20240531113931931](./会议&汇报&分享.assets/image-20240531113931931.png)

![image-20240531115319752](./会议&汇报&分享.assets/image-20240531115319752.png)

### 举两个例子

#### 代理模型判定是否必要检索

![image-20240531115702384](./会议&汇报&分享.assets/image-20240531115702384.png)

![image-20240531115710608](./会议&汇报&分享.assets/image-20240531115710608.png)

![image-20240531115901576](./会议&汇报&分享.assets/image-20240531115901576.png)

> 相关性：大概率
>
> - 大模型答不对的时候小模型也答不对
> - 小模型能答对的时候大模型也能答对

![image-20240531120043341](./会议&汇报&分享.assets/image-20240531120043341.png)

> **用同源的、轻量级的模型来代替大模型去做检索的判定**

![image-20240531120618933](./会议&汇报&分享.assets/image-20240531120618933.png)

> **性价比取舍**：虽然比仅用用户输入进行判断的方法高了一些开销，但是效果上看是必要的

#### 假设做完检索了，是否所有检索结果都是必要的？

![image-20240531120757054](./会议&汇报&分享.assets/image-20240531120757054.png)

![image-20240531120829486](./会议&汇报&分享.assets/image-20240531120829486.png)

![image-20240531130851733](./会议&汇报&分享.assets/image-20240531130851733.png)

![image-20240531130909968](./会议&汇报&分享.assets/image-20240531130909968.png)

### Toolkit：FlashRAG

![image-20240531131215891](./会议&汇报&分享.assets/image-20240531131215891.png)

![image-20240531131223218](./会议&汇报&分享.assets/image-20240531131223218.png)

![image-20240531131234230](./会议&汇报&分享.assets/image-20240531131234230.png)

![image-20240531131254466](./会议&汇报&分享.assets/image-20240531131254466.png)

![image-20240531131402816](./会议&汇报&分享.assets/image-20240531131402816.png)

![image-20240531131421297](./会议&汇报&分享.assets/image-20240531131421297.png)

## 生成式文档检索

![image-20240531131511414](./会议&汇报&分享.assets/image-20240531131511414.png)

![image-20240531131757192](./会议&汇报&分享.assets/image-20240531131757192.png)

### 生成式检索的范式

![image-20240531131847947](./会议&汇报&分享.assets/image-20240531131847947.png)

> 从解码器开始，把所有的文档ID通过前缀树构建起来，然后从边一直找到叶节点，输出一个正确的文档ID，整个生成的概率就作为相关性概率输出了

![image-20240531132537901](./会议&汇报&分享.assets/image-20240531132537901.png)

![image-20240531132637100](./会议&汇报&分享.assets/image-20240531132637100.png)



## 总结

- 未来的信息检索会逐渐往**生成**的方向演进
- 但是检索还是逃不掉的，未来的检索会变成同时为人和大模型服务的基础设置





